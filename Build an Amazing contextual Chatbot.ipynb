{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Build an Amazing contextual Chatbot.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPro+/uyNlDqBOvZmzktQig"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### **Libraries needed for NLP**"],"metadata":{"id":"X_Ja3f84uq55"}},{"cell_type":"code","execution_count":154,"metadata":{"id":"Csh54RZ5Fexy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660672723466,"user_tz":-330,"elapsed":416,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}},"outputId":"225ff32e-947c-4789-96b7-5945ff2dcb82"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","from nltk.stem.lancaster import LancasterStemmer\n","stemmer = LancasterStemmer()"]},{"cell_type":"markdown","source":["### **Libraries needed for Tensorflow processing**"],"metadata":{"id":"Mys0UUp9vcQ7"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import tflearn\n","import random\n","import json"],"metadata":{"id":"6ra_smzWvQRP","executionInfo":{"status":"ok","timestamp":1660672724145,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":155,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"id":"aBcQMVI7yAkZ","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"status":"ok","timestamp":1660672736092,"user_tz":-330,"elapsed":11955,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}},"outputId":"4ab7abcf-71e3-4cba-f804-99348de7ad8e"},"execution_count":156,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-e9698db1-fb7c-4c6c-bff4-866c66e4bc29\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-e9698db1-fb7c-4c6c-bff4-866c66e4bc29\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving intents.json to intents (5).json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'intents.json': b'{\"intents\": [\\n        {\"tag\": \"greeting\",\\n         \"patterns\": [\"Hi\", \"How are you\", \"Is anyone there?\", \"Hello\", \"Good day\"],\\n         \"responses\": [\"Hello, thanks for visiting\", \"Good to see you again\", \"Hi there, how can I help?\"],\\n         \"context_set\": \"\"\\n        },\\n        {\"tag\": \"goodbye\",\\n         \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\\n         \"responses\": [\"See you later, thanks for visiting\", \"Have a nice day\", \"Bye! Come back again soon.\"]\\n        },\\n        {\"tag\": \"thanks\",\\n         \"patterns\": [\"Thanks\", \"Thank you\", \"That\\'s helpful\"],\\n         \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\"]\\n        },\\n        {\"tag\": \"hours\",\\n         \"patterns\": [\"What hours are you open?\", \"What are your hours?\", \"When are you open?\" ],\\n         \"responses\": [\"We\\'re open every day 9am-9pm\", \"Our hours are 9am-9pm every day\"]\\n        },\\n        {\"tag\": \"location\",\\n         \"patterns\": [\"What is your location?\", \"Where are you located?\", \"What is your address?\", \"Where is your restaurant situated?\" ],\\n         \"responses\": [\"We are on the intersection of London Alley and Bridge Avenue.\", \"We are situated at the intersection of London Alley and Bridge Avenue\", \"Our Address is: 1000 Bridge Avenue, London EC3N 4AJ, UK\"]\\n        },\\n        {\"tag\": \"payments\",\\n         \"patterns\": [\"Do you take credit cards?\", \"Do you accept Mastercard?\", \"Are you cash only?\" ],\\n         \"responses\": [\"We accept VISA, Mastercard and AMEX\", \"We accept most major credit cards\"]\\n        },\\n        {\"tag\": \"todaysmenu\",\\n         \"patterns\": [\"What is your menu for today?\", \"What are you serving today?\", \"What is today\\'s special?\"],\\n         \"responses\": [\"Today\\'s special is Chicken Tikka\", \"Our speciality for today is Chicken Tikka\"]\\n        },\\n        {\"tag\": \"deliveryoption\",\\n         \"patterns\": [\"Do you provide home delivery?\", \"Do you deliver the food?\", \"What are the home delivery options?\" ],\\n         \"responses\": [\"Yes, we provide home delivery through UBER Eats and Zomato?\", \"We have home delivery options through UBER Eats and Zomato\"],\\n         \"context_set\": \"food\"\\n        },\\n        {\"tag\": \"menu\",\\n         \"patterns\": [\"What is your Menu?\", \"What are the main course options?\", \"Can you tell me the most delicious dish from the menu?\", \"What is the today\\'s special?\"],\\n         \"responses\": [\"You can visit www.mymenu.com for menu options\", \"You can check out the food menu at www.mymenu.com\", \"You can check various delicacies given in the food menu at www.mymenu.com\"],\\n         \"context_filter\": \"food\"\\n        }\\n   ]\\n}\\n'}"]},"metadata":{},"execution_count":156}]},{"cell_type":"markdown","source":["### **import our chat-bot intents file**"],"metadata":{"id":"aE4_hd4B02UJ"}},{"cell_type":"code","source":["with open('intents.json') as json_data:\n","    intents = json.load(json_data)"],"metadata":{"id":"mIE3eHfY08TV","executionInfo":{"status":"ok","timestamp":1660672736095,"user_tz":-330,"elapsed":18,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":157,"outputs":[]},{"cell_type":"code","source":["intents"],"metadata":{"id":"otN3AGm11Dkc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660672736095,"user_tz":-330,"elapsed":17,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}},"outputId":"9f9e4f18-02df-431d-ec72-9007ff3b4c7b"},"execution_count":158,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'intents': [{'tag': 'greeting',\n","   'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day'],\n","   'responses': ['Hello, thanks for visiting',\n","    'Good to see you again',\n","    'Hi there, how can I help?'],\n","   'context_set': ''},\n","  {'tag': 'goodbye',\n","   'patterns': ['Bye', 'See you later', 'Goodbye'],\n","   'responses': ['See you later, thanks for visiting',\n","    'Have a nice day',\n","    'Bye! Come back again soon.']},\n","  {'tag': 'thanks',\n","   'patterns': ['Thanks', 'Thank you', \"That's helpful\"],\n","   'responses': ['Happy to help!', 'Any time!', 'My pleasure']},\n","  {'tag': 'hours',\n","   'patterns': ['What hours are you open?',\n","    'What are your hours?',\n","    'When are you open?'],\n","   'responses': [\"We're open every day 9am-9pm\",\n","    'Our hours are 9am-9pm every day']},\n","  {'tag': 'location',\n","   'patterns': ['What is your location?',\n","    'Where are you located?',\n","    'What is your address?',\n","    'Where is your restaurant situated?'],\n","   'responses': ['We are on the intersection of London Alley and Bridge Avenue.',\n","    'We are situated at the intersection of London Alley and Bridge Avenue',\n","    'Our Address is: 1000 Bridge Avenue, London EC3N 4AJ, UK']},\n","  {'tag': 'payments',\n","   'patterns': ['Do you take credit cards?',\n","    'Do you accept Mastercard?',\n","    'Are you cash only?'],\n","   'responses': ['We accept VISA, Mastercard and AMEX',\n","    'We accept most major credit cards']},\n","  {'tag': 'todaysmenu',\n","   'patterns': ['What is your menu for today?',\n","    'What are you serving today?',\n","    \"What is today's special?\"],\n","   'responses': [\"Today's special is Chicken Tikka\",\n","    'Our speciality for today is Chicken Tikka']},\n","  {'tag': 'deliveryoption',\n","   'patterns': ['Do you provide home delivery?',\n","    'Do you deliver the food?',\n","    'What are the home delivery options?'],\n","   'responses': ['Yes, we provide home delivery through UBER Eats and Zomato?',\n","    'We have home delivery options through UBER Eats and Zomato'],\n","   'context_set': 'food'},\n","  {'tag': 'menu',\n","   'patterns': ['What is your Menu?',\n","    'What are the main course options?',\n","    'Can you tell me the most delicious dish from the menu?',\n","    \"What is the today's special?\"],\n","   'responses': ['You can visit www.mymenu.com for menu options',\n","    'You can check out the food menu at www.mymenu.com',\n","    'You can check various delicacies given in the food menu at www.mymenu.com'],\n","   'context_filter': 'food'}]}"]},"metadata":{},"execution_count":158}]},{"cell_type":"code","source":["words = []\n","classes = []\n","documents = []\n","ignore = ['?']"],"metadata":{"id":"VyA3sH7y1KzS","executionInfo":{"status":"ok","timestamp":1660672736096,"user_tz":-330,"elapsed":16,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":159,"outputs":[]},{"cell_type":"markdown","source":["**loop through each sentence in the intent's patterns**"],"metadata":{"id":"5_oQDrBh1R_h"}},{"cell_type":"code","source":["for intent in intents['intents']:\n","    for pattern in intent['patterns']:\n","        # tokenize each and every word in the sentence\n","        w = nltk.word_tokenize(pattern)\n","        # add word to the words list\n","        words.extend(w)\n","        # add word(s) to documents\n","        documents.append((w, intent['tag']))\n","        # add tags to our classes list\n","        if intent['tag'] not in classes:\n","            classes.append(intent['tag'])"],"metadata":{"id":"3inZ4mR01V3v","executionInfo":{"status":"ok","timestamp":1660672736096,"user_tz":-330,"elapsed":15,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":160,"outputs":[]},{"cell_type":"markdown","source":["**Perform stemming and lower each word as well as remove duplicates**"],"metadata":{"id":"3P4fO1PK1kK3"}},{"cell_type":"code","source":["words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\n","words = sorted(list(set(words)))"],"metadata":{"id":"8RRTC_GY1oOi","executionInfo":{"status":"ok","timestamp":1660672736096,"user_tz":-330,"elapsed":15,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":161,"outputs":[]},{"cell_type":"markdown","source":["**remove duplicate classes**"],"metadata":{"id":"zumLYQdC11YV"}},{"cell_type":"code","source":["classes = sorted(list(set(classes)))\n","\n","print (len(documents), \"documents\")\n","print (len(classes), \"classes\", classes)\n","print (len(words), \"unique stemmed words\", words)\n"],"metadata":{"id":"lNplBDWK15vo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660672736096,"user_tz":-330,"elapsed":15,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}},"outputId":"50c5b7d5-0fac-4b20-8eb7-1e5814cb3831"},"execution_count":162,"outputs":[{"output_type":"stream","name":"stdout","text":["31 documents\n","9 classes ['deliveryoption', 'goodbye', 'greeting', 'hours', 'location', 'menu', 'payments', 'thanks', 'todaysmenu']\n","57 unique stemmed words [\"'s\", 'acceiv', 'address', 'anyon', 'ar', 'bye', 'can', 'card', 'cash', 'cours', 'credit', 'day', 'del', 'delicy', 'delivery', 'dish', 'do', 'food', 'for', 'from', 'good', 'goodby', 'hello', 'help', 'hi', 'hom', 'hour', 'how', 'is', 'lat', 'loc', 'main', 'mastercard', 'me', 'menu', 'most', 'on', 'op', 'opt', 'provid', 'resta', 'see', 'serv', 'situ', 'spec', 'tak', 'tel', 'thank', 'that', 'the', 'ther', 'today', 'what', 'when', 'wher', 'yo', 'you']\n"]}]},{"cell_type":"markdown","source":["**create training data**"],"metadata":{"id":"fiUtSJQi-bmf"}},{"cell_type":"code","source":["training = []\n","output = []\n","# create an empty array for output\n","output_empty = [0] * len(classes)"],"metadata":{"id":"FQ1ck7MU-fch","executionInfo":{"status":"ok","timestamp":1660672736097,"user_tz":-330,"elapsed":13,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":163,"outputs":[]},{"cell_type":"markdown","source":["**create training set, bag of words for each sentence**"],"metadata":{"id":"bC9ulmch-5Jq"}},{"cell_type":"code","source":["for doc in documents:\n","    # initialize bag of words\n","    bag = []\n","    # list of tokenized words for the pattern\n","    pattern_words = doc[0]\n","    # stemming each word\n","    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n","    # create bag of words array\n","    for w in words:\n","        bag.append(1) if w in pattern_words else bag.append(0)"],"metadata":{"id":"kdoTYN3l-8AR","executionInfo":{"status":"ok","timestamp":1660672736097,"user_tz":-330,"elapsed":13,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":164,"outputs":[]},{"cell_type":"markdown","source":["**output is '1' for current tag and '0' for rest of other tags**"],"metadata":{"id":"9bz3mDFI_EYk"}},{"cell_type":"code","source":[" output_row = list(output_empty)\n"," output_row[classes.index(doc[1])] = 1\n","\n"," training.append([bag, output_row])\n"],"metadata":{"id":"jnWtXrDL_HaU","executionInfo":{"status":"ok","timestamp":1660672736097,"user_tz":-330,"elapsed":12,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":165,"outputs":[]},{"cell_type":"markdown","source":["**shuffling features and turning it into np.array**"],"metadata":{"id":"Bt7iZ7l3_Xh8"}},{"cell_type":"code","source":["random.shuffle(training)\n","training = np.array(training)\n"],"metadata":{"id":"HVvk7g11_cCH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660672736097,"user_tz":-330,"elapsed":12,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}},"outputId":"885f342a-bd25-4c38-8ca1-fc59e4ef4320"},"execution_count":166,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  \n"]}]},{"cell_type":"markdown","source":[" creating training lists"],"metadata":{"id":"D-ZVzdyo_n79"}},{"cell_type":"code","source":["train_x = list(training[:,0])\n","train_y = list(training[:,1])"],"metadata":{"id":"zRjWS8eT_q-s","executionInfo":{"status":"ok","timestamp":1660672736098,"user_tz":-330,"elapsed":11,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":167,"outputs":[]},{"cell_type":"markdown","source":["**resetting underlying graph data**"],"metadata":{"id":"CgujT17i_ydz"}},{"cell_type":"code","source":["tf.compat.v1.reset_default_graph()"],"metadata":{"id":"Nylmb1Lp_uC2","executionInfo":{"status":"ok","timestamp":1660672736098,"user_tz":-330,"elapsed":11,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":168,"outputs":[]},{"cell_type":"markdown","source":["**Building neural network**"],"metadata":{"id":"Os0vmRILAIwk"}},{"cell_type":"code","source":["net = tflearn.input_data(shape=[None, len(train_x[0])])\n","net = tflearn.fully_connected(net, 10)\n","net = tflearn.fully_connected(net, 10)\n","net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n","net = tflearn.regression(net)\n","\n"],"metadata":{"id":"8gQK8V9LALNj","executionInfo":{"status":"ok","timestamp":1660672736814,"user_tz":-330,"elapsed":727,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":169,"outputs":[]},{"cell_type":"markdown","source":["** Defining model and setting up tensorboard**"],"metadata":{"id":"up7XEp4oBt5S"}},{"cell_type":"code","source":["model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')"],"metadata":{"id":"WEYCEJMzANbJ","executionInfo":{"status":"ok","timestamp":1660672736815,"user_tz":-330,"elapsed":42,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":170,"outputs":[]},{"cell_type":"markdown","source":["**Start training**"],"metadata":{"id":"BEsHGc_SB9Zr"}},{"cell_type":"code","source":["model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)\n","model.save('model.tflearn')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xsAwpOB9CEkh","outputId":"9d7395dd-7abb-4839-e649-cd0fae5dd08a","executionInfo":{"status":"ok","timestamp":1660672754651,"user_tz":-330,"elapsed":17878,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":171,"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------------------\n","Run id: 6FEHP7\n","Log directory: tflearn_logs/\n","---------------------------------\n","Training samples: 1\n","Validation samples: 0\n","--\n","Training Step: 1  | time: 0.101s\n","\u001b[2K\r| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 1/1\n","--\n","Training Step: 2  | total loss: \u001b[1m\u001b[32m2.15557\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 002 | loss: 2.15557 - acc: 0.0000 -- iter: 1/1\n","--\n","Training Step: 3  | total loss: \u001b[1m\u001b[32m2.18368\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 003 | loss: 2.18368 - acc: 0.8182 -- iter: 1/1\n","--\n","Training Step: 4  | total loss: \u001b[1m\u001b[32m2.18368\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 004 | loss: 2.18368 - acc: 0.9545 -- iter: 1/1\n","--\n","Training Step: 5  | total loss: \u001b[1m\u001b[32m2.18876\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 005 | loss: 2.18876 - acc: 0.9860 -- iter: 1/1\n","--\n","Training Step: 6  | total loss: \u001b[1m\u001b[32m2.18876\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 006 | loss: 2.18876 - acc: 0.9950 -- iter: 1/1\n","--\n","Training Step: 7  | total loss: \u001b[1m\u001b[32m2.18566\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 007 | loss: 2.18566 - acc: 0.9980 -- iter: 1/1\n","--\n","Training Step: 8  | total loss: \u001b[1m\u001b[32m2.18566\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 008 | loss: 2.18566 - acc: 0.9991 -- iter: 1/1\n","--\n","Training Step: 9  | total loss: \u001b[1m\u001b[32m2.18156\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 009 | loss: 2.18156 - acc: 0.9996 -- iter: 1/1\n","--\n","Training Step: 10  | total loss: \u001b[1m\u001b[32m2.17934\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 010 | loss: 2.17934 - acc: 0.9998 -- iter: 1/1\n","--\n","Training Step: 11  | total loss: \u001b[1m\u001b[32m2.17702\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 011 | loss: 2.17702 - acc: 0.9999 -- iter: 1/1\n","--\n","Training Step: 12  | total loss: \u001b[1m\u001b[32m2.17460\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 012 | loss: 2.17460 - acc: 0.9999 -- iter: 1/1\n","--\n","Training Step: 13  | total loss: \u001b[1m\u001b[32m2.17460\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 013 | loss: 2.17460 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 14  | total loss: \u001b[1m\u001b[32m2.17207\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 014 | loss: 2.17207 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 15  | total loss: \u001b[1m\u001b[32m2.16666\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 015 | loss: 2.16666 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 16  | total loss: \u001b[1m\u001b[32m2.16666\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 016 | loss: 2.16666 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 17  | total loss: \u001b[1m\u001b[32m2.16070\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 017 | loss: 2.16070 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 18  | total loss: \u001b[1m\u001b[32m2.15748\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 018 | loss: 2.15748 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 19  | total loss: \u001b[1m\u001b[32m2.15748\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 019 | loss: 2.15748 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 20  | total loss: \u001b[1m\u001b[32m2.15410\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 020 | loss: 2.15410 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 21  | total loss: \u001b[1m\u001b[32m2.14676\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 021 | loss: 2.14676 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 22  | total loss: \u001b[1m\u001b[32m2.14277\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 022 | loss: 2.14277 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 23  | total loss: \u001b[1m\u001b[32m2.14277\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 023 | loss: 2.14277 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 24  | total loss: \u001b[1m\u001b[32m2.13411\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 024 | loss: 2.13411 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 25  | total loss: \u001b[1m\u001b[32m2.12939\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 025 | loss: 2.12939 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 26  | total loss: \u001b[1m\u001b[32m2.12939\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 026 | loss: 2.12939 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 27  | total loss: \u001b[1m\u001b[32m2.11911\u001b[0m\u001b[0m | time: 0.002s\n","| Adam | epoch: 027 | loss: 2.11911 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 28  | total loss: \u001b[1m\u001b[32m2.11350\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 028 | loss: 2.11350 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 29  | total loss: \u001b[1m\u001b[32m2.11350\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 029 | loss: 2.11350 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 30  | total loss: \u001b[1m\u001b[32m2.10757\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 030 | loss: 2.10757 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 31  | total loss: \u001b[1m\u001b[32m2.09463\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 031 | loss: 2.09463 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 32  | total loss: \u001b[1m\u001b[32m2.08757\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 032 | loss: 2.08757 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 33  | total loss: \u001b[1m\u001b[32m2.08757\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 033 | loss: 2.08757 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 34  | total loss: \u001b[1m\u001b[32m2.08011\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 034 | loss: 2.08011 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 35  | total loss: \u001b[1m\u001b[32m2.06386\u001b[0m\u001b[0m | time: 0.002s\n","| Adam | epoch: 035 | loss: 2.06386 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 36  | total loss: \u001b[1m\u001b[32m2.05503\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 036 | loss: 2.05503 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 37  | total loss: \u001b[1m\u001b[32m2.04569\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 037 | loss: 2.04569 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 38  | total loss: \u001b[1m\u001b[32m2.04569\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 038 | loss: 2.04569 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 39  | total loss: \u001b[1m\u001b[32m2.03583\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 039 | loss: 2.03583 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 40  | total loss: \u001b[1m\u001b[32m2.02542\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 040 | loss: 2.02542 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 41  | total loss: \u001b[1m\u001b[32m2.00287\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 041 | loss: 2.00287 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 42  | total loss: \u001b[1m\u001b[32m1.99067\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 042 | loss: 1.99067 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 43  | total loss: \u001b[1m\u001b[32m1.99067\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 043 | loss: 1.99067 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 44  | total loss: \u001b[1m\u001b[32m1.97783\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 044 | loss: 1.97783 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 45  | total loss: \u001b[1m\u001b[32m1.96433\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 045 | loss: 1.96433 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 46  | total loss: \u001b[1m\u001b[32m1.93522\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 046 | loss: 1.93522 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 47  | total loss: \u001b[1m\u001b[32m1.93522\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 047 | loss: 1.93522 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 48  | total loss: \u001b[1m\u001b[32m1.91957\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 048 | loss: 1.91957 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 49  | total loss: \u001b[1m\u001b[32m1.88598\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 049 | loss: 1.88598 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 50  | total loss: \u001b[1m\u001b[32m1.86798\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 050 | loss: 1.86798 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 51  | total loss: \u001b[1m\u001b[32m1.84917\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 051 | loss: 1.84917 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 52  | total loss: \u001b[1m\u001b[32m1.82951\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 052 | loss: 1.82951 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 53  | total loss: \u001b[1m\u001b[32m1.80899\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 053 | loss: 1.80899 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 54  | total loss: \u001b[1m\u001b[32m1.80899\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 054 | loss: 1.80899 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 55  | total loss: \u001b[1m\u001b[32m1.76531\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 055 | loss: 1.76531 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 56  | total loss: \u001b[1m\u001b[32m1.76531\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 056 | loss: 1.76531 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 57  | total loss: \u001b[1m\u001b[32m1.74211\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 057 | loss: 1.74211 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 58  | total loss: \u001b[1m\u001b[32m1.69297\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 058 | loss: 1.69297 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 59  | total loss: \u001b[1m\u001b[32m1.66700\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 059 | loss: 1.66700 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 60  | total loss: \u001b[1m\u001b[32m1.64011\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 060 | loss: 1.64011 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 61  | total loss: \u001b[1m\u001b[32m1.64011\u001b[0m\u001b[0m | time: 0.002s\n","| Adam | epoch: 061 | loss: 1.64011 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 62  | total loss: \u001b[1m\u001b[32m1.61228\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 062 | loss: 1.61228 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 63  | total loss: \u001b[1m\u001b[32m1.55385\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 063 | loss: 1.55385 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 64  | total loss: \u001b[1m\u001b[32m1.52328\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 064 | loss: 1.52328 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 65  | total loss: \u001b[1m\u001b[32m1.49181\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 065 | loss: 1.49181 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 66  | total loss: \u001b[1m\u001b[32m1.49181\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 066 | loss: 1.49181 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 67  | total loss: \u001b[1m\u001b[32m1.45948\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 067 | loss: 1.45948 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 68  | total loss: \u001b[1m\u001b[32m1.42632\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 068 | loss: 1.42632 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 69  | total loss: \u001b[1m\u001b[32m1.35764\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 069 | loss: 1.35764 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 70  | total loss: \u001b[1m\u001b[32m1.32221\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 070 | loss: 1.32221 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 71  | total loss: \u001b[1m\u001b[32m1.28612\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 071 | loss: 1.28612 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 72  | total loss: \u001b[1m\u001b[32m1.28612\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 072 | loss: 1.28612 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 73  | total loss: \u001b[1m\u001b[32m1.21224\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 073 | loss: 1.21224 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 74  | total loss: \u001b[1m\u001b[32m1.17459\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 074 | loss: 1.17459 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 75  | total loss: \u001b[1m\u001b[32m1.13658\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 075 | loss: 1.13658 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 76  | total loss: \u001b[1m\u001b[32m1.13658\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 076 | loss: 1.13658 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 77  | total loss: \u001b[1m\u001b[32m1.09829\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 077 | loss: 1.09829 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 78  | total loss: \u001b[1m\u001b[32m1.02128\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 078 | loss: 1.02128 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 79  | total loss: \u001b[1m\u001b[32m1.02128\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 079 | loss: 1.02128 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 80  | total loss: \u001b[1m\u001b[32m0.98276\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 080 | loss: 0.98276 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 81  | total loss: \u001b[1m\u001b[32m0.94437\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 081 | loss: 0.94437 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 82  | total loss: \u001b[1m\u001b[32m0.90623\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 082 | loss: 0.90623 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 83  | total loss: \u001b[1m\u001b[32m0.86802\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 083 | loss: 0.86802 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 84  | total loss: \u001b[1m\u001b[32m0.79205\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 084 | loss: 0.79205 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 85  | total loss: \u001b[1m\u001b[32m0.79205\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 085 | loss: 0.79205 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 86  | total loss: \u001b[1m\u001b[32m0.71767\u001b[0m\u001b[0m | time: 0.012s\n","| Adam | epoch: 086 | loss: 0.71767 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 87  | total loss: \u001b[1m\u001b[32m0.71767\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 087 | loss: 0.71767 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 88  | total loss: \u001b[1m\u001b[32m0.68143\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 088 | loss: 0.68143 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 89  | total loss: \u001b[1m\u001b[32m0.64599\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 089 | loss: 0.64599 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 90  | total loss: \u001b[1m\u001b[32m0.57793\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 090 | loss: 0.57793 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 91  | total loss: \u001b[1m\u001b[32m0.54548\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 091 | loss: 0.54548 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 92  | total loss: \u001b[1m\u001b[32m0.51419\u001b[0m\u001b[0m | time: 0.012s\n","| Adam | epoch: 092 | loss: 0.51419 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 93  | total loss: \u001b[1m\u001b[32m0.48411\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 093 | loss: 0.48411 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 94  | total loss: \u001b[1m\u001b[32m0.45528\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 094 | loss: 0.45528 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 95  | total loss: \u001b[1m\u001b[32m0.45528\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 095 | loss: 0.45528 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 96  | total loss: \u001b[1m\u001b[32m0.42773\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 096 | loss: 0.42773 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 97  | total loss: \u001b[1m\u001b[32m0.37650\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 097 | loss: 0.37650 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 98  | total loss: \u001b[1m\u001b[32m0.37650\u001b[0m\u001b[0m | time: 0.012s\n","| Adam | epoch: 098 | loss: 0.37650 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 99  | total loss: \u001b[1m\u001b[32m0.35282\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 099 | loss: 0.35282 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 100  | total loss: \u001b[1m\u001b[32m0.30926\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 100 | loss: 0.30926 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 101  | total loss: \u001b[1m\u001b[32m0.28931\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 101 | loss: 0.28931 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 102  | total loss: \u001b[1m\u001b[32m0.27055\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 102 | loss: 0.27055 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 103  | total loss: \u001b[1m\u001b[32m0.25293\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 103 | loss: 0.25293 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 104  | total loss: \u001b[1m\u001b[32m0.23641\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 104 | loss: 0.23641 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 105  | total loss: \u001b[1m\u001b[32m0.23641\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 105 | loss: 0.23641 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 106  | total loss: \u001b[1m\u001b[32m0.22093\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 106 | loss: 0.22093 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 107  | total loss: \u001b[1m\u001b[32m0.20645\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 107 | loss: 0.20645 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 108  | total loss: \u001b[1m\u001b[32m0.18031\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 108 | loss: 0.18031 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 109  | total loss: \u001b[1m\u001b[32m0.16854\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 109 | loss: 0.16854 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 110  | total loss: \u001b[1m\u001b[32m0.15758\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 110 | loss: 0.15758 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 111  | total loss: \u001b[1m\u001b[32m0.14738\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 111 | loss: 0.14738 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 112  | total loss: \u001b[1m\u001b[32m0.13788\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 112 | loss: 0.13788 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 113  | total loss: \u001b[1m\u001b[32m0.12906\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 113 | loss: 0.12906 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 114  | total loss: \u001b[1m\u001b[32m0.12086\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 114 | loss: 0.12086 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 115  | total loss: \u001b[1m\u001b[32m0.11324\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 115 | loss: 0.11324 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 116  | total loss: \u001b[1m\u001b[32m0.10617\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 116 | loss: 0.10617 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 117  | total loss: \u001b[1m\u001b[32m0.09960\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 117 | loss: 0.09960 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 118  | total loss: \u001b[1m\u001b[32m0.09351\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 118 | loss: 0.09351 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 119  | total loss: \u001b[1m\u001b[32m0.08786\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 119 | loss: 0.08786 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 120  | total loss: \u001b[1m\u001b[32m0.08262\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 120 | loss: 0.08262 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 121  | total loss: \u001b[1m\u001b[32m0.07776\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 121 | loss: 0.07776 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 122  | total loss: \u001b[1m\u001b[32m0.07324\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 122 | loss: 0.07324 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 123  | total loss: \u001b[1m\u001b[32m0.06906\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 123 | loss: 0.06906 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 124  | total loss: \u001b[1m\u001b[32m0.06518\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 124 | loss: 0.06518 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 125  | total loss: \u001b[1m\u001b[32m0.06158\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 125 | loss: 0.06158 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 126  | total loss: \u001b[1m\u001b[32m0.05823\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 126 | loss: 0.05823 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 127  | total loss: \u001b[1m\u001b[32m0.05513\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 127 | loss: 0.05513 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 128  | total loss: \u001b[1m\u001b[32m0.05225\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 128 | loss: 0.05225 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 129  | total loss: \u001b[1m\u001b[32m0.04957\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 129 | loss: 0.04957 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 130  | total loss: \u001b[1m\u001b[32m0.04709\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 130 | loss: 0.04709 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 131  | total loss: \u001b[1m\u001b[32m0.04709\u001b[0m\u001b[0m | time: 0.019s\n","| Adam | epoch: 131 | loss: 0.04709 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 132  | total loss: \u001b[1m\u001b[32m0.04263\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 132 | loss: 0.04263 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 133  | total loss: \u001b[1m\u001b[32m0.04063\u001b[0m\u001b[0m | time: 0.013s\n","| Adam | epoch: 133 | loss: 0.04063 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 134  | total loss: \u001b[1m\u001b[32m0.03877\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 134 | loss: 0.03877 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 135  | total loss: \u001b[1m\u001b[32m0.03704\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 135 | loss: 0.03704 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 136  | total loss: \u001b[1m\u001b[32m0.03542\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 136 | loss: 0.03542 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 137  | total loss: \u001b[1m\u001b[32m0.03392\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 137 | loss: 0.03392 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 138  | total loss: \u001b[1m\u001b[32m0.03392\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 138 | loss: 0.03392 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 139  | total loss: \u001b[1m\u001b[32m0.03120\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 139 | loss: 0.03120 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 140  | total loss: \u001b[1m\u001b[32m0.02997\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 140 | loss: 0.02997 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 141  | total loss: \u001b[1m\u001b[32m0.02883\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 141 | loss: 0.02883 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 142  | total loss: \u001b[1m\u001b[32m0.02775\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 142 | loss: 0.02775 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 143  | total loss: \u001b[1m\u001b[32m0.02675\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 143 | loss: 0.02675 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 144  | total loss: \u001b[1m\u001b[32m0.02675\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 144 | loss: 0.02675 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 145  | total loss: \u001b[1m\u001b[32m0.02492\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 145 | loss: 0.02492 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 146  | total loss: \u001b[1m\u001b[32m0.02409\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 146 | loss: 0.02409 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 147  | total loss: \u001b[1m\u001b[32m0.02331\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 147 | loss: 0.02331 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 148  | total loss: \u001b[1m\u001b[32m0.02258\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 148 | loss: 0.02258 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 149  | total loss: \u001b[1m\u001b[32m0.02258\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 149 | loss: 0.02258 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 150  | total loss: \u001b[1m\u001b[32m0.02188\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 150 | loss: 0.02188 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 151  | total loss: \u001b[1m\u001b[32m0.02123\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 151 | loss: 0.02123 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 152  | total loss: \u001b[1m\u001b[32m0.02062\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 152 | loss: 0.02062 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 153  | total loss: \u001b[1m\u001b[32m0.02003\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 153 | loss: 0.02003 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 154  | total loss: \u001b[1m\u001b[32m0.01896\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 154 | loss: 0.01896 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 155  | total loss: \u001b[1m\u001b[32m0.01847\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 155 | loss: 0.01847 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 156  | total loss: \u001b[1m\u001b[32m0.01800\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 156 | loss: 0.01800 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 157  | total loss: \u001b[1m\u001b[32m0.01800\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 157 | loss: 0.01800 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 158  | total loss: \u001b[1m\u001b[32m0.01756\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 158 | loss: 0.01756 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 159  | total loss: \u001b[1m\u001b[32m0.01713\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 159 | loss: 0.01713 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 160  | total loss: \u001b[1m\u001b[32m0.01673\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 160 | loss: 0.01673 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 161  | total loss: \u001b[1m\u001b[32m0.01598\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 161 | loss: 0.01598 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 162  | total loss: \u001b[1m\u001b[32m0.01598\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 162 | loss: 0.01598 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 163  | total loss: \u001b[1m\u001b[32m0.01563\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 163 | loss: 0.01563 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 164  | total loss: \u001b[1m\u001b[32m0.01530\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 164 | loss: 0.01530 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 165  | total loss: \u001b[1m\u001b[32m0.01498\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 165 | loss: 0.01498 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 166  | total loss: \u001b[1m\u001b[32m0.01438\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 166 | loss: 0.01438 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 167  | total loss: \u001b[1m\u001b[32m0.01410\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 167 | loss: 0.01410 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 168  | total loss: \u001b[1m\u001b[32m0.01383\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 168 | loss: 0.01383 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 169  | total loss: \u001b[1m\u001b[32m0.01357\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 169 | loss: 0.01357 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 170  | total loss: \u001b[1m\u001b[32m0.01332\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 170 | loss: 0.01332 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 171  | total loss: \u001b[1m\u001b[32m0.01308\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 171 | loss: 0.01308 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 172  | total loss: \u001b[1m\u001b[32m0.01285\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 172 | loss: 0.01285 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 173  | total loss: \u001b[1m\u001b[32m0.01263\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 173 | loss: 0.01263 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 174  | total loss: \u001b[1m\u001b[32m0.01241\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 174 | loss: 0.01241 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 175  | total loss: \u001b[1m\u001b[32m0.01241\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 175 | loss: 0.01241 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 176  | total loss: \u001b[1m\u001b[32m0.01200\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 176 | loss: 0.01200 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 177  | total loss: \u001b[1m\u001b[32m0.01181\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 177 | loss: 0.01181 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 178  | total loss: \u001b[1m\u001b[32m0.01162\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 178 | loss: 0.01162 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 179  | total loss: \u001b[1m\u001b[32m0.01144\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 179 | loss: 0.01144 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 180  | total loss: \u001b[1m\u001b[32m0.01126\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 180 | loss: 0.01126 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 181  | total loss: \u001b[1m\u001b[32m0.01109\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 181 | loss: 0.01109 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 182  | total loss: \u001b[1m\u001b[32m0.01092\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 182 | loss: 0.01092 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 183  | total loss: \u001b[1m\u001b[32m0.01076\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 183 | loss: 0.01076 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 184  | total loss: \u001b[1m\u001b[32m0.01060\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 184 | loss: 0.01060 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 185  | total loss: \u001b[1m\u001b[32m0.01045\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 185 | loss: 0.01045 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 186  | total loss: \u001b[1m\u001b[32m0.01030\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 186 | loss: 0.01030 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 187  | total loss: \u001b[1m\u001b[32m0.01016\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 187 | loss: 0.01016 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 188  | total loss: \u001b[1m\u001b[32m0.01002\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 188 | loss: 0.01002 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 189  | total loss: \u001b[1m\u001b[32m0.00988\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 189 | loss: 0.00988 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 190  | total loss: \u001b[1m\u001b[32m0.00974\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 190 | loss: 0.00974 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 191  | total loss: \u001b[1m\u001b[32m0.00961\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 191 | loss: 0.00961 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 192  | total loss: \u001b[1m\u001b[32m0.00949\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 192 | loss: 0.00949 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 193  | total loss: \u001b[1m\u001b[32m0.00936\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 193 | loss: 0.00936 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 194  | total loss: \u001b[1m\u001b[32m0.00924\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 194 | loss: 0.00924 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 195  | total loss: \u001b[1m\u001b[32m0.00912\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 195 | loss: 0.00912 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 196  | total loss: \u001b[1m\u001b[32m0.00900\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 196 | loss: 0.00900 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 197  | total loss: \u001b[1m\u001b[32m0.00889\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 197 | loss: 0.00889 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 198  | total loss: \u001b[1m\u001b[32m0.00878\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 198 | loss: 0.00878 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 199  | total loss: \u001b[1m\u001b[32m0.00867\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 199 | loss: 0.00867 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 200  | total loss: \u001b[1m\u001b[32m0.00867\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 200 | loss: 0.00867 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 201  | total loss: \u001b[1m\u001b[32m0.00857\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 201 | loss: 0.00857 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 202  | total loss: \u001b[1m\u001b[32m0.00836\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 202 | loss: 0.00836 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 203  | total loss: \u001b[1m\u001b[32m0.00826\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 203 | loss: 0.00826 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 204  | total loss: \u001b[1m\u001b[32m0.00816\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 204 | loss: 0.00816 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 205  | total loss: \u001b[1m\u001b[32m0.00807\u001b[0m\u001b[0m | time: 0.020s\n","| Adam | epoch: 205 | loss: 0.00807 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 206  | total loss: \u001b[1m\u001b[32m0.00797\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 206 | loss: 0.00797 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 207  | total loss: \u001b[1m\u001b[32m0.00788\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 207 | loss: 0.00788 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 208  | total loss: \u001b[1m\u001b[32m0.00779\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 208 | loss: 0.00779 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 209  | total loss: \u001b[1m\u001b[32m0.00770\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 209 | loss: 0.00770 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 210  | total loss: \u001b[1m\u001b[32m0.00770\u001b[0m\u001b[0m | time: 0.012s\n","| Adam | epoch: 210 | loss: 0.00770 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 211  | total loss: \u001b[1m\u001b[32m0.00762\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 211 | loss: 0.00762 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 212  | total loss: \u001b[1m\u001b[32m0.00745\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 212 | loss: 0.00745 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 213  | total loss: \u001b[1m\u001b[32m0.00737\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 213 | loss: 0.00737 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 214  | total loss: \u001b[1m\u001b[32m0.00729\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 214 | loss: 0.00729 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 215  | total loss: \u001b[1m\u001b[32m0.00721\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 215 | loss: 0.00721 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 216  | total loss: \u001b[1m\u001b[32m0.00713\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 216 | loss: 0.00713 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 217  | total loss: \u001b[1m\u001b[32m0.00706\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 217 | loss: 0.00706 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 218  | total loss: \u001b[1m\u001b[32m0.00698\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 218 | loss: 0.00698 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 219  | total loss: \u001b[1m\u001b[32m0.00691\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 219 | loss: 0.00691 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 220  | total loss: \u001b[1m\u001b[32m0.00684\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 220 | loss: 0.00684 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 221  | total loss: \u001b[1m\u001b[32m0.00676\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 221 | loss: 0.00676 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 222  | total loss: \u001b[1m\u001b[32m0.00669\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 222 | loss: 0.00669 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 223  | total loss: \u001b[1m\u001b[32m0.00663\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 223 | loss: 0.00663 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 224  | total loss: \u001b[1m\u001b[32m0.00656\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 224 | loss: 0.00656 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 225  | total loss: \u001b[1m\u001b[32m0.00649\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 225 | loss: 0.00649 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 226  | total loss: \u001b[1m\u001b[32m0.00643\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 226 | loss: 0.00643 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 227  | total loss: \u001b[1m\u001b[32m0.00636\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 227 | loss: 0.00636 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 228  | total loss: \u001b[1m\u001b[32m0.00630\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 228 | loss: 0.00630 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 229  | total loss: \u001b[1m\u001b[32m0.00624\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 229 | loss: 0.00624 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 230  | total loss: \u001b[1m\u001b[32m0.00618\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 230 | loss: 0.00618 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 231  | total loss: \u001b[1m\u001b[32m0.00612\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 231 | loss: 0.00612 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 232  | total loss: \u001b[1m\u001b[32m0.00606\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 232 | loss: 0.00606 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 233  | total loss: \u001b[1m\u001b[32m0.00600\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 233 | loss: 0.00600 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 234  | total loss: \u001b[1m\u001b[32m0.00594\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 234 | loss: 0.00594 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 235  | total loss: \u001b[1m\u001b[32m0.00589\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 235 | loss: 0.00589 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 236  | total loss: \u001b[1m\u001b[32m0.00583\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 236 | loss: 0.00583 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 237  | total loss: \u001b[1m\u001b[32m0.00578\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 237 | loss: 0.00578 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 238  | total loss: \u001b[1m\u001b[32m0.00572\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 238 | loss: 0.00572 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 239  | total loss: \u001b[1m\u001b[32m0.00567\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 239 | loss: 0.00567 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 240  | total loss: \u001b[1m\u001b[32m0.00562\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 240 | loss: 0.00562 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 241  | total loss: \u001b[1m\u001b[32m0.00556\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 241 | loss: 0.00556 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 242  | total loss: \u001b[1m\u001b[32m0.00551\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 242 | loss: 0.00551 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 243  | total loss: \u001b[1m\u001b[32m0.00546\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 243 | loss: 0.00546 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 244  | total loss: \u001b[1m\u001b[32m0.00541\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 244 | loss: 0.00541 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 245  | total loss: \u001b[1m\u001b[32m0.00537\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 245 | loss: 0.00537 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 246  | total loss: \u001b[1m\u001b[32m0.00532\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 246 | loss: 0.00532 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 247  | total loss: \u001b[1m\u001b[32m0.00527\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 247 | loss: 0.00527 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 248  | total loss: \u001b[1m\u001b[32m0.00522\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 248 | loss: 0.00522 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 249  | total loss: \u001b[1m\u001b[32m0.00518\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 249 | loss: 0.00518 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 250  | total loss: \u001b[1m\u001b[32m0.00513\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 250 | loss: 0.00513 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 251  | total loss: \u001b[1m\u001b[32m0.00509\u001b[0m\u001b[0m | time: 0.012s\n","| Adam | epoch: 251 | loss: 0.00509 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 252  | total loss: \u001b[1m\u001b[32m0.00505\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 252 | loss: 0.00505 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 253  | total loss: \u001b[1m\u001b[32m0.00500\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 253 | loss: 0.00500 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 254  | total loss: \u001b[1m\u001b[32m0.00496\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 254 | loss: 0.00496 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 255  | total loss: \u001b[1m\u001b[32m0.00492\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 255 | loss: 0.00492 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 256  | total loss: \u001b[1m\u001b[32m0.00488\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 256 | loss: 0.00488 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 257  | total loss: \u001b[1m\u001b[32m0.00483\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 257 | loss: 0.00483 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 258  | total loss: \u001b[1m\u001b[32m0.00479\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 258 | loss: 0.00479 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 259  | total loss: \u001b[1m\u001b[32m0.00475\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 259 | loss: 0.00475 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 260  | total loss: \u001b[1m\u001b[32m0.00471\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 260 | loss: 0.00471 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 261  | total loss: \u001b[1m\u001b[32m0.00468\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 261 | loss: 0.00468 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 262  | total loss: \u001b[1m\u001b[32m0.00464\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 262 | loss: 0.00464 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 263  | total loss: \u001b[1m\u001b[32m0.00464\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 263 | loss: 0.00464 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 264  | total loss: \u001b[1m\u001b[32m0.00456\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 264 | loss: 0.00456 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 265  | total loss: \u001b[1m\u001b[32m0.00452\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 265 | loss: 0.00452 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 266  | total loss: \u001b[1m\u001b[32m0.00449\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 266 | loss: 0.00449 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 267  | total loss: \u001b[1m\u001b[32m0.00449\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 267 | loss: 0.00449 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 268  | total loss: \u001b[1m\u001b[32m0.00445\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 268 | loss: 0.00445 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 269  | total loss: \u001b[1m\u001b[32m0.00442\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 269 | loss: 0.00442 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 270  | total loss: \u001b[1m\u001b[32m0.00435\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 270 | loss: 0.00435 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 271  | total loss: \u001b[1m\u001b[32m0.00431\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 271 | loss: 0.00431 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 272  | total loss: \u001b[1m\u001b[32m0.00431\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 272 | loss: 0.00431 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 273  | total loss: \u001b[1m\u001b[32m0.00425\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 273 | loss: 0.00425 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 274  | total loss: \u001b[1m\u001b[32m0.00421\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 274 | loss: 0.00421 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 275  | total loss: \u001b[1m\u001b[32m0.00418\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 275 | loss: 0.00418 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 276  | total loss: \u001b[1m\u001b[32m0.00415\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 276 | loss: 0.00415 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 277  | total loss: \u001b[1m\u001b[32m0.00412\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 277 | loss: 0.00412 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 278  | total loss: \u001b[1m\u001b[32m0.00408\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 278 | loss: 0.00408 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 279  | total loss: \u001b[1m\u001b[32m0.00405\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 279 | loss: 0.00405 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 280  | total loss: \u001b[1m\u001b[32m0.00405\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 280 | loss: 0.00405 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 281  | total loss: \u001b[1m\u001b[32m0.00399\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 281 | loss: 0.00399 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 282  | total loss: \u001b[1m\u001b[32m0.00396\u001b[0m\u001b[0m | time: 0.012s\n","| Adam | epoch: 282 | loss: 0.00396 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 283  | total loss: \u001b[1m\u001b[32m0.00393\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 283 | loss: 0.00393 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 284  | total loss: \u001b[1m\u001b[32m0.00390\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 284 | loss: 0.00390 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 285  | total loss: \u001b[1m\u001b[32m0.00390\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 285 | loss: 0.00390 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 286  | total loss: \u001b[1m\u001b[32m0.00385\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 286 | loss: 0.00385 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 287  | total loss: \u001b[1m\u001b[32m0.00382\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 287 | loss: 0.00382 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 288  | total loss: \u001b[1m\u001b[32m0.00379\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 288 | loss: 0.00379 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 289  | total loss: \u001b[1m\u001b[32m0.00379\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 289 | loss: 0.00379 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 290  | total loss: \u001b[1m\u001b[32m0.00376\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 290 | loss: 0.00376 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 291  | total loss: \u001b[1m\u001b[32m0.00371\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 291 | loss: 0.00371 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 292  | total loss: \u001b[1m\u001b[32m0.00371\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 292 | loss: 0.00371 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 293  | total loss: \u001b[1m\u001b[32m0.00366\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 293 | loss: 0.00366 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 294  | total loss: \u001b[1m\u001b[32m0.00363\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 294 | loss: 0.00363 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 295  | total loss: \u001b[1m\u001b[32m0.00360\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 295 | loss: 0.00360 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 296  | total loss: \u001b[1m\u001b[32m0.00358\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 296 | loss: 0.00358 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 297  | total loss: \u001b[1m\u001b[32m0.00355\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 297 | loss: 0.00355 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 298  | total loss: \u001b[1m\u001b[32m0.00353\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 298 | loss: 0.00353 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 299  | total loss: \u001b[1m\u001b[32m0.00353\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 299 | loss: 0.00353 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 300  | total loss: \u001b[1m\u001b[32m0.00348\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 300 | loss: 0.00348 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 301  | total loss: \u001b[1m\u001b[32m0.00346\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 301 | loss: 0.00346 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 302  | total loss: \u001b[1m\u001b[32m0.00343\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 302 | loss: 0.00343 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 303  | total loss: \u001b[1m\u001b[32m0.00341\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 303 | loss: 0.00341 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 304  | total loss: \u001b[1m\u001b[32m0.00338\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 304 | loss: 0.00338 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 305  | total loss: \u001b[1m\u001b[32m0.00336\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 305 | loss: 0.00336 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 306  | total loss: \u001b[1m\u001b[32m0.00334\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 306 | loss: 0.00334 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 307  | total loss: \u001b[1m\u001b[32m0.00332\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 307 | loss: 0.00332 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 308  | total loss: \u001b[1m\u001b[32m0.00329\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 308 | loss: 0.00329 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 309  | total loss: \u001b[1m\u001b[32m0.00327\u001b[0m\u001b[0m | time: 0.013s\n","| Adam | epoch: 309 | loss: 0.00327 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 310  | total loss: \u001b[1m\u001b[32m0.00325\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 310 | loss: 0.00325 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 311  | total loss: \u001b[1m\u001b[32m0.00323\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 311 | loss: 0.00323 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 312  | total loss: \u001b[1m\u001b[32m0.00321\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 312 | loss: 0.00321 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 313  | total loss: \u001b[1m\u001b[32m0.00319\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 313 | loss: 0.00319 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 314  | total loss: \u001b[1m\u001b[32m0.00316\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 314 | loss: 0.00316 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 315  | total loss: \u001b[1m\u001b[32m0.00314\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 315 | loss: 0.00314 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 316  | total loss: \u001b[1m\u001b[32m0.00312\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 316 | loss: 0.00312 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 317  | total loss: \u001b[1m\u001b[32m0.00310\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 317 | loss: 0.00310 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 318  | total loss: \u001b[1m\u001b[32m0.00308\u001b[0m\u001b[0m | time: 0.013s\n","| Adam | epoch: 318 | loss: 0.00308 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 319  | total loss: \u001b[1m\u001b[32m0.00308\u001b[0m\u001b[0m | time: 0.014s\n","| Adam | epoch: 319 | loss: 0.00308 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 320  | total loss: \u001b[1m\u001b[32m0.00306\u001b[0m\u001b[0m | time: 0.012s\n","| Adam | epoch: 320 | loss: 0.00306 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 321  | total loss: \u001b[1m\u001b[32m0.00304\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 321 | loss: 0.00304 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 322  | total loss: \u001b[1m\u001b[32m0.00300\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 322 | loss: 0.00300 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 323  | total loss: \u001b[1m\u001b[32m0.00300\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 323 | loss: 0.00300 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 324  | total loss: \u001b[1m\u001b[32m0.00299\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 324 | loss: 0.00299 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 325  | total loss: \u001b[1m\u001b[32m0.00295\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 325 | loss: 0.00295 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 326  | total loss: \u001b[1m\u001b[32m0.00293\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 326 | loss: 0.00293 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 327  | total loss: \u001b[1m\u001b[32m0.00291\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 327 | loss: 0.00291 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 328  | total loss: \u001b[1m\u001b[32m0.00289\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 328 | loss: 0.00289 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 329  | total loss: \u001b[1m\u001b[32m0.00287\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 329 | loss: 0.00287 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 330  | total loss: \u001b[1m\u001b[32m0.00286\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 330 | loss: 0.00286 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 331  | total loss: \u001b[1m\u001b[32m0.00286\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 331 | loss: 0.00286 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 332  | total loss: \u001b[1m\u001b[32m0.00282\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 332 | loss: 0.00282 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 333  | total loss: \u001b[1m\u001b[32m0.00280\u001b[0m\u001b[0m | time: 0.013s\n","| Adam | epoch: 333 | loss: 0.00280 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 334  | total loss: \u001b[1m\u001b[32m0.00279\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 334 | loss: 0.00279 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 335  | total loss: \u001b[1m\u001b[32m0.00277\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 335 | loss: 0.00277 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 336  | total loss: \u001b[1m\u001b[32m0.00275\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 336 | loss: 0.00275 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 337  | total loss: \u001b[1m\u001b[32m0.00274\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 337 | loss: 0.00274 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 338  | total loss: \u001b[1m\u001b[32m0.00272\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 338 | loss: 0.00272 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 339  | total loss: \u001b[1m\u001b[32m0.00270\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 339 | loss: 0.00270 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 340  | total loss: \u001b[1m\u001b[32m0.00269\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 340 | loss: 0.00269 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 341  | total loss: \u001b[1m\u001b[32m0.00267\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 341 | loss: 0.00267 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 342  | total loss: \u001b[1m\u001b[32m0.00266\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 342 | loss: 0.00266 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 343  | total loss: \u001b[1m\u001b[32m0.00264\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 343 | loss: 0.00264 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 344  | total loss: \u001b[1m\u001b[32m0.00262\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 344 | loss: 0.00262 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 345  | total loss: \u001b[1m\u001b[32m0.00261\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 345 | loss: 0.00261 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 346  | total loss: \u001b[1m\u001b[32m0.00259\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 346 | loss: 0.00259 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 347  | total loss: \u001b[1m\u001b[32m0.00258\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 347 | loss: 0.00258 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 348  | total loss: \u001b[1m\u001b[32m0.00256\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 348 | loss: 0.00256 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 349  | total loss: \u001b[1m\u001b[32m0.00255\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 349 | loss: 0.00255 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 350  | total loss: \u001b[1m\u001b[32m0.00253\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 350 | loss: 0.00253 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 351  | total loss: \u001b[1m\u001b[32m0.00253\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 351 | loss: 0.00253 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 352  | total loss: \u001b[1m\u001b[32m0.00250\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 352 | loss: 0.00250 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 353  | total loss: \u001b[1m\u001b[32m0.00249\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 353 | loss: 0.00249 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 354  | total loss: \u001b[1m\u001b[32m0.00248\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 354 | loss: 0.00248 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 355  | total loss: \u001b[1m\u001b[32m0.00246\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 355 | loss: 0.00246 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 356  | total loss: \u001b[1m\u001b[32m0.00246\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 356 | loss: 0.00246 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 357  | total loss: \u001b[1m\u001b[32m0.00243\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 357 | loss: 0.00243 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 358  | total loss: \u001b[1m\u001b[32m0.00243\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 358 | loss: 0.00243 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 359  | total loss: \u001b[1m\u001b[32m0.00242\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 359 | loss: 0.00242 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 360  | total loss: \u001b[1m\u001b[32m0.00241\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 360 | loss: 0.00241 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 361  | total loss: \u001b[1m\u001b[32m0.00239\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 361 | loss: 0.00239 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 362  | total loss: \u001b[1m\u001b[32m0.00238\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 362 | loss: 0.00238 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 363  | total loss: \u001b[1m\u001b[32m0.00237\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 363 | loss: 0.00237 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 364  | total loss: \u001b[1m\u001b[32m0.00235\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 364 | loss: 0.00235 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 365  | total loss: \u001b[1m\u001b[32m0.00234\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 365 | loss: 0.00234 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 366  | total loss: \u001b[1m\u001b[32m0.00231\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 366 | loss: 0.00231 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 367  | total loss: \u001b[1m\u001b[32m0.00230\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 367 | loss: 0.00230 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 368  | total loss: \u001b[1m\u001b[32m0.00229\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 368 | loss: 0.00229 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 369  | total loss: \u001b[1m\u001b[32m0.00228\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 369 | loss: 0.00228 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 370  | total loss: \u001b[1m\u001b[32m0.00226\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 370 | loss: 0.00226 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 371  | total loss: \u001b[1m\u001b[32m0.00225\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 371 | loss: 0.00225 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 372  | total loss: \u001b[1m\u001b[32m0.00224\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 372 | loss: 0.00224 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 373  | total loss: \u001b[1m\u001b[32m0.00223\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 373 | loss: 0.00223 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 374  | total loss: \u001b[1m\u001b[32m0.00221\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 374 | loss: 0.00221 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 375  | total loss: \u001b[1m\u001b[32m0.00221\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 375 | loss: 0.00221 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 376  | total loss: \u001b[1m\u001b[32m0.00220\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 376 | loss: 0.00220 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 377  | total loss: \u001b[1m\u001b[32m0.00219\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 377 | loss: 0.00219 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 378  | total loss: \u001b[1m\u001b[32m0.00218\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 378 | loss: 0.00218 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 379  | total loss: \u001b[1m\u001b[32m0.00217\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 379 | loss: 0.00217 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 380  | total loss: \u001b[1m\u001b[32m0.00216\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 380 | loss: 0.00216 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 381  | total loss: \u001b[1m\u001b[32m0.00214\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 381 | loss: 0.00214 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 382  | total loss: \u001b[1m\u001b[32m0.00213\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 382 | loss: 0.00213 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 383  | total loss: \u001b[1m\u001b[32m0.00212\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 383 | loss: 0.00212 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 384  | total loss: \u001b[1m\u001b[32m0.00211\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 384 | loss: 0.00211 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 385  | total loss: \u001b[1m\u001b[32m0.00210\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 385 | loss: 0.00210 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 386  | total loss: \u001b[1m\u001b[32m0.00209\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 386 | loss: 0.00209 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 387  | total loss: \u001b[1m\u001b[32m0.00208\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 387 | loss: 0.00208 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 388  | total loss: \u001b[1m\u001b[32m0.00207\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 388 | loss: 0.00207 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 389  | total loss: \u001b[1m\u001b[32m0.00206\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 389 | loss: 0.00206 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 390  | total loss: \u001b[1m\u001b[32m0.00205\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 390 | loss: 0.00205 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 391  | total loss: \u001b[1m\u001b[32m0.00204\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 391 | loss: 0.00204 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 392  | total loss: \u001b[1m\u001b[32m0.00203\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 392 | loss: 0.00203 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 393  | total loss: \u001b[1m\u001b[32m0.00202\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 393 | loss: 0.00202 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 394  | total loss: \u001b[1m\u001b[32m0.00199\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 394 | loss: 0.00199 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 395  | total loss: \u001b[1m\u001b[32m0.00198\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 395 | loss: 0.00198 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 396  | total loss: \u001b[1m\u001b[32m0.00197\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 396 | loss: 0.00197 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 397  | total loss: \u001b[1m\u001b[32m0.00196\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 397 | loss: 0.00196 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 398  | total loss: \u001b[1m\u001b[32m0.00196\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 398 | loss: 0.00196 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 399  | total loss: \u001b[1m\u001b[32m0.00195\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 399 | loss: 0.00195 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 400  | total loss: \u001b[1m\u001b[32m0.00194\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 400 | loss: 0.00194 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 401  | total loss: \u001b[1m\u001b[32m0.00194\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 401 | loss: 0.00194 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 402  | total loss: \u001b[1m\u001b[32m0.00193\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 402 | loss: 0.00193 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 403  | total loss: \u001b[1m\u001b[32m0.00192\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 403 | loss: 0.00192 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 404  | total loss: \u001b[1m\u001b[32m0.00191\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 404 | loss: 0.00191 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 405  | total loss: \u001b[1m\u001b[32m0.00190\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 405 | loss: 0.00190 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 406  | total loss: \u001b[1m\u001b[32m0.00189\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 406 | loss: 0.00189 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 407  | total loss: \u001b[1m\u001b[32m0.00188\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 407 | loss: 0.00188 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 408  | total loss: \u001b[1m\u001b[32m0.00187\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 408 | loss: 0.00187 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 409  | total loss: \u001b[1m\u001b[32m0.00186\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 409 | loss: 0.00186 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 410  | total loss: \u001b[1m\u001b[32m0.00185\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 410 | loss: 0.00185 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 411  | total loss: \u001b[1m\u001b[32m0.00184\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 411 | loss: 0.00184 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 412  | total loss: \u001b[1m\u001b[32m0.00183\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 412 | loss: 0.00183 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 413  | total loss: \u001b[1m\u001b[32m0.00182\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 413 | loss: 0.00182 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 414  | total loss: \u001b[1m\u001b[32m0.00182\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 414 | loss: 0.00182 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 415  | total loss: \u001b[1m\u001b[32m0.00181\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 415 | loss: 0.00181 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 416  | total loss: \u001b[1m\u001b[32m0.00179\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 416 | loss: 0.00179 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 417  | total loss: \u001b[1m\u001b[32m0.00178\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 417 | loss: 0.00178 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 418  | total loss: \u001b[1m\u001b[32m0.00177\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 418 | loss: 0.00177 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 419  | total loss: \u001b[1m\u001b[32m0.00176\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 419 | loss: 0.00176 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 420  | total loss: \u001b[1m\u001b[32m0.00176\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 420 | loss: 0.00176 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 421  | total loss: \u001b[1m\u001b[32m0.00175\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 421 | loss: 0.00175 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 422  | total loss: \u001b[1m\u001b[32m0.00174\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 422 | loss: 0.00174 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 423  | total loss: \u001b[1m\u001b[32m0.00173\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 423 | loss: 0.00173 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 424  | total loss: \u001b[1m\u001b[32m0.00172\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 424 | loss: 0.00172 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 425  | total loss: \u001b[1m\u001b[32m0.00171\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 425 | loss: 0.00171 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 426  | total loss: \u001b[1m\u001b[32m0.00171\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 426 | loss: 0.00171 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 427  | total loss: \u001b[1m\u001b[32m0.00170\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 427 | loss: 0.00170 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 428  | total loss: \u001b[1m\u001b[32m0.00169\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 428 | loss: 0.00169 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 429  | total loss: \u001b[1m\u001b[32m0.00168\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 429 | loss: 0.00168 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 430  | total loss: \u001b[1m\u001b[32m0.00168\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 430 | loss: 0.00168 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 431  | total loss: \u001b[1m\u001b[32m0.00167\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 431 | loss: 0.00167 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 432  | total loss: \u001b[1m\u001b[32m0.00166\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 432 | loss: 0.00166 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 433  | total loss: \u001b[1m\u001b[32m0.00166\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 433 | loss: 0.00166 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 434  | total loss: \u001b[1m\u001b[32m0.00164\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 434 | loss: 0.00164 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 435  | total loss: \u001b[1m\u001b[32m0.00164\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 435 | loss: 0.00164 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 436  | total loss: \u001b[1m\u001b[32m0.00163\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 436 | loss: 0.00163 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 437  | total loss: \u001b[1m\u001b[32m0.00162\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 437 | loss: 0.00162 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 438  | total loss: \u001b[1m\u001b[32m0.00162\u001b[0m\u001b[0m | time: 0.013s\n","| Adam | epoch: 438 | loss: 0.00162 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 439  | total loss: \u001b[1m\u001b[32m0.00161\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 439 | loss: 0.00161 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 440  | total loss: \u001b[1m\u001b[32m0.00160\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 440 | loss: 0.00160 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 441  | total loss: \u001b[1m\u001b[32m0.00159\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 441 | loss: 0.00159 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 442  | total loss: \u001b[1m\u001b[32m0.00159\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 442 | loss: 0.00159 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 443  | total loss: \u001b[1m\u001b[32m0.00158\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 443 | loss: 0.00158 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 444  | total loss: \u001b[1m\u001b[32m0.00157\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 444 | loss: 0.00157 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 445  | total loss: \u001b[1m\u001b[32m0.00157\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 445 | loss: 0.00157 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 446  | total loss: \u001b[1m\u001b[32m0.00156\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 446 | loss: 0.00156 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 447  | total loss: \u001b[1m\u001b[32m0.00156\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 447 | loss: 0.00156 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 448  | total loss: \u001b[1m\u001b[32m0.00154\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 448 | loss: 0.00154 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 449  | total loss: \u001b[1m\u001b[32m0.00154\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 449 | loss: 0.00154 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 450  | total loss: \u001b[1m\u001b[32m0.00154\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 450 | loss: 0.00154 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 451  | total loss: \u001b[1m\u001b[32m0.00153\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 451 | loss: 0.00153 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 452  | total loss: \u001b[1m\u001b[32m0.00152\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 452 | loss: 0.00152 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 453  | total loss: \u001b[1m\u001b[32m0.00152\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 453 | loss: 0.00152 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 454  | total loss: \u001b[1m\u001b[32m0.00150\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 454 | loss: 0.00150 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 455  | total loss: \u001b[1m\u001b[32m0.00150\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 455 | loss: 0.00150 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 456  | total loss: \u001b[1m\u001b[32m0.00149\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 456 | loss: 0.00149 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 457  | total loss: \u001b[1m\u001b[32m0.00148\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 457 | loss: 0.00148 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 458  | total loss: \u001b[1m\u001b[32m0.00148\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 458 | loss: 0.00148 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 459  | total loss: \u001b[1m\u001b[32m0.00147\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 459 | loss: 0.00147 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 460  | total loss: \u001b[1m\u001b[32m0.00147\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 460 | loss: 0.00147 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 461  | total loss: \u001b[1m\u001b[32m0.00146\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 461 | loss: 0.00146 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 462  | total loss: \u001b[1m\u001b[32m0.00145\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 462 | loss: 0.00145 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 463  | total loss: \u001b[1m\u001b[32m0.00145\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 463 | loss: 0.00145 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 464  | total loss: \u001b[1m\u001b[32m0.00144\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 464 | loss: 0.00144 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 465  | total loss: \u001b[1m\u001b[32m0.00143\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 465 | loss: 0.00143 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 466  | total loss: \u001b[1m\u001b[32m0.00143\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 466 | loss: 0.00143 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 467  | total loss: \u001b[1m\u001b[32m0.00142\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 467 | loss: 0.00142 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 468  | total loss: \u001b[1m\u001b[32m0.00142\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 468 | loss: 0.00142 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 469  | total loss: \u001b[1m\u001b[32m0.00141\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 469 | loss: 0.00141 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 470  | total loss: \u001b[1m\u001b[32m0.00140\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 470 | loss: 0.00140 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 471  | total loss: \u001b[1m\u001b[32m0.00140\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 471 | loss: 0.00140 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 472  | total loss: \u001b[1m\u001b[32m0.00139\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 472 | loss: 0.00139 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 473  | total loss: \u001b[1m\u001b[32m0.00139\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 473 | loss: 0.00139 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 474  | total loss: \u001b[1m\u001b[32m0.00138\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 474 | loss: 0.00138 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 475  | total loss: \u001b[1m\u001b[32m0.00138\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 475 | loss: 0.00138 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 476  | total loss: \u001b[1m\u001b[32m0.00137\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 476 | loss: 0.00137 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 477  | total loss: \u001b[1m\u001b[32m0.00136\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 477 | loss: 0.00136 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 478  | total loss: \u001b[1m\u001b[32m0.00136\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 478 | loss: 0.00136 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 479  | total loss: \u001b[1m\u001b[32m0.00135\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 479 | loss: 0.00135 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 480  | total loss: \u001b[1m\u001b[32m0.00135\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 480 | loss: 0.00135 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 481  | total loss: \u001b[1m\u001b[32m0.00134\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 481 | loss: 0.00134 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 482  | total loss: \u001b[1m\u001b[32m0.00134\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 482 | loss: 0.00134 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 483  | total loss: \u001b[1m\u001b[32m0.00133\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 483 | loss: 0.00133 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 484  | total loss: \u001b[1m\u001b[32m0.00133\u001b[0m\u001b[0m | time: 0.015s\n","| Adam | epoch: 484 | loss: 0.00133 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 485  | total loss: \u001b[1m\u001b[32m0.00132\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 485 | loss: 0.00132 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 486  | total loss: \u001b[1m\u001b[32m0.00131\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 486 | loss: 0.00131 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 487  | total loss: \u001b[1m\u001b[32m0.00131\u001b[0m\u001b[0m | time: 0.012s\n","| Adam | epoch: 487 | loss: 0.00131 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 488  | total loss: \u001b[1m\u001b[32m0.00130\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 488 | loss: 0.00130 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 489  | total loss: \u001b[1m\u001b[32m0.00130\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 489 | loss: 0.00130 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 490  | total loss: \u001b[1m\u001b[32m0.00129\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 490 | loss: 0.00129 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 491  | total loss: \u001b[1m\u001b[32m0.00129\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 491 | loss: 0.00129 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 492  | total loss: \u001b[1m\u001b[32m0.00128\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 492 | loss: 0.00128 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 493  | total loss: \u001b[1m\u001b[32m0.00128\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 493 | loss: 0.00128 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 494  | total loss: \u001b[1m\u001b[32m0.00128\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 494 | loss: 0.00128 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 495  | total loss: \u001b[1m\u001b[32m0.00127\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 495 | loss: 0.00127 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 496  | total loss: \u001b[1m\u001b[32m0.00126\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 496 | loss: 0.00126 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 497  | total loss: \u001b[1m\u001b[32m0.00126\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 497 | loss: 0.00126 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 498  | total loss: \u001b[1m\u001b[32m0.00125\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 498 | loss: 0.00125 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 499  | total loss: \u001b[1m\u001b[32m0.00125\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 499 | loss: 0.00125 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 500  | total loss: \u001b[1m\u001b[32m0.00124\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 500 | loss: 0.00124 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 501  | total loss: \u001b[1m\u001b[32m0.00124\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 501 | loss: 0.00124 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 502  | total loss: \u001b[1m\u001b[32m0.00123\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 502 | loss: 0.00123 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 503  | total loss: \u001b[1m\u001b[32m0.00123\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 503 | loss: 0.00123 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 504  | total loss: \u001b[1m\u001b[32m0.00122\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 504 | loss: 0.00122 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 505  | total loss: \u001b[1m\u001b[32m0.00122\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 505 | loss: 0.00122 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 506  | total loss: \u001b[1m\u001b[32m0.00121\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 506 | loss: 0.00121 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 507  | total loss: \u001b[1m\u001b[32m0.00121\u001b[0m\u001b[0m | time: 0.012s\n","| Adam | epoch: 507 | loss: 0.00121 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 508  | total loss: \u001b[1m\u001b[32m0.00121\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 508 | loss: 0.00121 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 509  | total loss: \u001b[1m\u001b[32m0.00120\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 509 | loss: 0.00120 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 510  | total loss: \u001b[1m\u001b[32m0.00120\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 510 | loss: 0.00120 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 511  | total loss: \u001b[1m\u001b[32m0.00119\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 511 | loss: 0.00119 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 512  | total loss: \u001b[1m\u001b[32m0.00119\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 512 | loss: 0.00119 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 513  | total loss: \u001b[1m\u001b[32m0.00118\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 513 | loss: 0.00118 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 514  | total loss: \u001b[1m\u001b[32m0.00118\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 514 | loss: 0.00118 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 515  | total loss: \u001b[1m\u001b[32m0.00117\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 515 | loss: 0.00117 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 516  | total loss: \u001b[1m\u001b[32m0.00117\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 516 | loss: 0.00117 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 517  | total loss: \u001b[1m\u001b[32m0.00116\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 517 | loss: 0.00116 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 518  | total loss: \u001b[1m\u001b[32m0.00116\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 518 | loss: 0.00116 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 519  | total loss: \u001b[1m\u001b[32m0.00116\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 519 | loss: 0.00116 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 520  | total loss: \u001b[1m\u001b[32m0.00116\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 520 | loss: 0.00116 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 521  | total loss: \u001b[1m\u001b[32m0.00115\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 521 | loss: 0.00115 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 522  | total loss: \u001b[1m\u001b[32m0.00114\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 522 | loss: 0.00114 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 523  | total loss: \u001b[1m\u001b[32m0.00114\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 523 | loss: 0.00114 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 524  | total loss: \u001b[1m\u001b[32m0.00113\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 524 | loss: 0.00113 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 525  | total loss: \u001b[1m\u001b[32m0.00113\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 525 | loss: 0.00113 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 526  | total loss: \u001b[1m\u001b[32m0.00113\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 526 | loss: 0.00113 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 527  | total loss: \u001b[1m\u001b[32m0.00112\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 527 | loss: 0.00112 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 528  | total loss: \u001b[1m\u001b[32m0.00112\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 528 | loss: 0.00112 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 529  | total loss: \u001b[1m\u001b[32m0.00111\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 529 | loss: 0.00111 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 530  | total loss: \u001b[1m\u001b[32m0.00111\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 530 | loss: 0.00111 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 531  | total loss: \u001b[1m\u001b[32m0.00110\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 531 | loss: 0.00110 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 532  | total loss: \u001b[1m\u001b[32m0.00110\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 532 | loss: 0.00110 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 533  | total loss: \u001b[1m\u001b[32m0.00110\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 533 | loss: 0.00110 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 534  | total loss: \u001b[1m\u001b[32m0.00109\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 534 | loss: 0.00109 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 535  | total loss: \u001b[1m\u001b[32m0.00109\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 535 | loss: 0.00109 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 536  | total loss: \u001b[1m\u001b[32m0.00108\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 536 | loss: 0.00108 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 537  | total loss: \u001b[1m\u001b[32m0.00108\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 537 | loss: 0.00108 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 538  | total loss: \u001b[1m\u001b[32m0.00108\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 538 | loss: 0.00108 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 539  | total loss: \u001b[1m\u001b[32m0.00107\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 539 | loss: 0.00107 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 540  | total loss: \u001b[1m\u001b[32m0.00107\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 540 | loss: 0.00107 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 541  | total loss: \u001b[1m\u001b[32m0.00107\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 541 | loss: 0.00107 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 542  | total loss: \u001b[1m\u001b[32m0.00107\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 542 | loss: 0.00107 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 543  | total loss: \u001b[1m\u001b[32m0.00106\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 543 | loss: 0.00106 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 544  | total loss: \u001b[1m\u001b[32m0.00105\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 544 | loss: 0.00105 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 545  | total loss: \u001b[1m\u001b[32m0.00105\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 545 | loss: 0.00105 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 546  | total loss: \u001b[1m\u001b[32m0.00105\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 546 | loss: 0.00105 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 547  | total loss: \u001b[1m\u001b[32m0.00104\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 547 | loss: 0.00104 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 548  | total loss: \u001b[1m\u001b[32m0.00104\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 548 | loss: 0.00104 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 549  | total loss: \u001b[1m\u001b[32m0.00103\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 549 | loss: 0.00103 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 550  | total loss: \u001b[1m\u001b[32m0.00103\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 550 | loss: 0.00103 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 551  | total loss: \u001b[1m\u001b[32m0.00103\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 551 | loss: 0.00103 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 552  | total loss: \u001b[1m\u001b[32m0.00102\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 552 | loss: 0.00102 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 553  | total loss: \u001b[1m\u001b[32m0.00102\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 553 | loss: 0.00102 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 554  | total loss: \u001b[1m\u001b[32m0.00102\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 554 | loss: 0.00102 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 555  | total loss: \u001b[1m\u001b[32m0.00101\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 555 | loss: 0.00101 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 556  | total loss: \u001b[1m\u001b[32m0.00101\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 556 | loss: 0.00101 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 557  | total loss: \u001b[1m\u001b[32m0.00101\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 557 | loss: 0.00101 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 558  | total loss: \u001b[1m\u001b[32m0.00100\u001b[0m\u001b[0m | time: 0.015s\n","| Adam | epoch: 558 | loss: 0.00100 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 559  | total loss: \u001b[1m\u001b[32m0.00100\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 559 | loss: 0.00100 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 560  | total loss: \u001b[1m\u001b[32m0.00100\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 560 | loss: 0.00100 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 561  | total loss: \u001b[1m\u001b[32m0.00099\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 561 | loss: 0.00099 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 562  | total loss: \u001b[1m\u001b[32m0.00099\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 562 | loss: 0.00099 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 563  | total loss: \u001b[1m\u001b[32m0.00099\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 563 | loss: 0.00099 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 564  | total loss: \u001b[1m\u001b[32m0.00099\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 564 | loss: 0.00099 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 565  | total loss: \u001b[1m\u001b[32m0.00098\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 565 | loss: 0.00098 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 566  | total loss: \u001b[1m\u001b[32m0.00098\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 566 | loss: 0.00098 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 567  | total loss: \u001b[1m\u001b[32m0.00097\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 567 | loss: 0.00097 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 568  | total loss: \u001b[1m\u001b[32m0.00097\u001b[0m\u001b[0m | time: 0.013s\n","| Adam | epoch: 568 | loss: 0.00097 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 569  | total loss: \u001b[1m\u001b[32m0.00097\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 569 | loss: 0.00097 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 570  | total loss: \u001b[1m\u001b[32m0.00096\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 570 | loss: 0.00096 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 571  | total loss: \u001b[1m\u001b[32m0.00096\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 571 | loss: 0.00096 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 572  | total loss: \u001b[1m\u001b[32m0.00096\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 572 | loss: 0.00096 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 573  | total loss: \u001b[1m\u001b[32m0.00096\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 573 | loss: 0.00096 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 574  | total loss: \u001b[1m\u001b[32m0.00095\u001b[0m\u001b[0m | time: 0.013s\n","| Adam | epoch: 574 | loss: 0.00095 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 575  | total loss: \u001b[1m\u001b[32m0.00095\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 575 | loss: 0.00095 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 576  | total loss: \u001b[1m\u001b[32m0.00094\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 576 | loss: 0.00094 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 577  | total loss: \u001b[1m\u001b[32m0.00094\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 577 | loss: 0.00094 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 578  | total loss: \u001b[1m\u001b[32m0.00094\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 578 | loss: 0.00094 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 579  | total loss: \u001b[1m\u001b[32m0.00094\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 579 | loss: 0.00094 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 580  | total loss: \u001b[1m\u001b[32m0.00093\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 580 | loss: 0.00093 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 581  | total loss: \u001b[1m\u001b[32m0.00093\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 581 | loss: 0.00093 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 582  | total loss: \u001b[1m\u001b[32m0.00093\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 582 | loss: 0.00093 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 583  | total loss: \u001b[1m\u001b[32m0.00092\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 583 | loss: 0.00092 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 584  | total loss: \u001b[1m\u001b[32m0.00092\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 584 | loss: 0.00092 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 585  | total loss: \u001b[1m\u001b[32m0.00091\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 585 | loss: 0.00091 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 586  | total loss: \u001b[1m\u001b[32m0.00091\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 586 | loss: 0.00091 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 587  | total loss: \u001b[1m\u001b[32m0.00091\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 587 | loss: 0.00091 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 588  | total loss: \u001b[1m\u001b[32m0.00090\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 588 | loss: 0.00090 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 589  | total loss: \u001b[1m\u001b[32m0.00090\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 589 | loss: 0.00090 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 590  | total loss: \u001b[1m\u001b[32m0.00090\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 590 | loss: 0.00090 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 591  | total loss: \u001b[1m\u001b[32m0.00090\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 591 | loss: 0.00090 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 592  | total loss: \u001b[1m\u001b[32m0.00089\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 592 | loss: 0.00089 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 593  | total loss: \u001b[1m\u001b[32m0.00089\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 593 | loss: 0.00089 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 594  | total loss: \u001b[1m\u001b[32m0.00089\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 594 | loss: 0.00089 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 595  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 595 | loss: 0.00088 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 596  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 596 | loss: 0.00088 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 597  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 597 | loss: 0.00088 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 598  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 598 | loss: 0.00088 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 599  | total loss: \u001b[1m\u001b[32m0.00087\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 599 | loss: 0.00087 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 600  | total loss: \u001b[1m\u001b[32m0.00087\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 600 | loss: 0.00087 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 601  | total loss: \u001b[1m\u001b[32m0.00087\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 601 | loss: 0.00087 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 602  | total loss: \u001b[1m\u001b[32m0.00086\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 602 | loss: 0.00086 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 603  | total loss: \u001b[1m\u001b[32m0.00086\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 603 | loss: 0.00086 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 604  | total loss: \u001b[1m\u001b[32m0.00086\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 604 | loss: 0.00086 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 605  | total loss: \u001b[1m\u001b[32m0.00086\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 605 | loss: 0.00086 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 606  | total loss: \u001b[1m\u001b[32m0.00085\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 606 | loss: 0.00085 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 607  | total loss: \u001b[1m\u001b[32m0.00085\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 607 | loss: 0.00085 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 608  | total loss: \u001b[1m\u001b[32m0.00085\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 608 | loss: 0.00085 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 609  | total loss: \u001b[1m\u001b[32m0.00084\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 609 | loss: 0.00084 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 610  | total loss: \u001b[1m\u001b[32m0.00084\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 610 | loss: 0.00084 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 611  | total loss: \u001b[1m\u001b[32m0.00084\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 611 | loss: 0.00084 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 612  | total loss: \u001b[1m\u001b[32m0.00084\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 612 | loss: 0.00084 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 613  | total loss: \u001b[1m\u001b[32m0.00083\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 613 | loss: 0.00083 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 614  | total loss: \u001b[1m\u001b[32m0.00083\u001b[0m\u001b[0m | time: 0.014s\n","| Adam | epoch: 614 | loss: 0.00083 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 615  | total loss: \u001b[1m\u001b[32m0.00083\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 615 | loss: 0.00083 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 616  | total loss: \u001b[1m\u001b[32m0.00083\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 616 | loss: 0.00083 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 617  | total loss: \u001b[1m\u001b[32m0.00082\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 617 | loss: 0.00082 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 618  | total loss: \u001b[1m\u001b[32m0.00082\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 618 | loss: 0.00082 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 619  | total loss: \u001b[1m\u001b[32m0.00082\u001b[0m\u001b[0m | time: 0.013s\n","| Adam | epoch: 619 | loss: 0.00082 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 620  | total loss: \u001b[1m\u001b[32m0.00082\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 620 | loss: 0.00082 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 621  | total loss: \u001b[1m\u001b[32m0.00081\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 621 | loss: 0.00081 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 622  | total loss: \u001b[1m\u001b[32m0.00081\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 622 | loss: 0.00081 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 623  | total loss: \u001b[1m\u001b[32m0.00081\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 623 | loss: 0.00081 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 624  | total loss: \u001b[1m\u001b[32m0.00081\u001b[0m\u001b[0m | time: 0.016s\n","| Adam | epoch: 624 | loss: 0.00081 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 625  | total loss: \u001b[1m\u001b[32m0.00080\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 625 | loss: 0.00080 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 626  | total loss: \u001b[1m\u001b[32m0.00080\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 626 | loss: 0.00080 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 627  | total loss: \u001b[1m\u001b[32m0.00080\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 627 | loss: 0.00080 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 628  | total loss: \u001b[1m\u001b[32m0.00080\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 628 | loss: 0.00080 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 629  | total loss: \u001b[1m\u001b[32m0.00079\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 629 | loss: 0.00079 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 630  | total loss: \u001b[1m\u001b[32m0.00079\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 630 | loss: 0.00079 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 631  | total loss: \u001b[1m\u001b[32m0.00079\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 631 | loss: 0.00079 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 632  | total loss: \u001b[1m\u001b[32m0.00079\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 632 | loss: 0.00079 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 633  | total loss: \u001b[1m\u001b[32m0.00079\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 633 | loss: 0.00079 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 634  | total loss: \u001b[1m\u001b[32m0.00078\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 634 | loss: 0.00078 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 635  | total loss: \u001b[1m\u001b[32m0.00078\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 635 | loss: 0.00078 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 636  | total loss: \u001b[1m\u001b[32m0.00078\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 636 | loss: 0.00078 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 637  | total loss: \u001b[1m\u001b[32m0.00078\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 637 | loss: 0.00078 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 638  | total loss: \u001b[1m\u001b[32m0.00077\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 638 | loss: 0.00077 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 639  | total loss: \u001b[1m\u001b[32m0.00077\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 639 | loss: 0.00077 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 640  | total loss: \u001b[1m\u001b[32m0.00077\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 640 | loss: 0.00077 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 641  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 641 | loss: 0.00076 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 642  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 642 | loss: 0.00076 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 643  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 643 | loss: 0.00076 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 644  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 644 | loss: 0.00076 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 645  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 645 | loss: 0.00076 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 646  | total loss: \u001b[1m\u001b[32m0.00075\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 646 | loss: 0.00075 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 647  | total loss: \u001b[1m\u001b[32m0.00075\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 647 | loss: 0.00075 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 648  | total loss: \u001b[1m\u001b[32m0.00075\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 648 | loss: 0.00075 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 649  | total loss: \u001b[1m\u001b[32m0.00075\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 649 | loss: 0.00075 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 650  | total loss: \u001b[1m\u001b[32m0.00075\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 650 | loss: 0.00075 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 651  | total loss: \u001b[1m\u001b[32m0.00074\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 651 | loss: 0.00074 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 652  | total loss: \u001b[1m\u001b[32m0.00074\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 652 | loss: 0.00074 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 653  | total loss: \u001b[1m\u001b[32m0.00074\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 653 | loss: 0.00074 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 654  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 654 | loss: 0.00073 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 655  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 655 | loss: 0.00073 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 656  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 656 | loss: 0.00073 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 657  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 657 | loss: 0.00073 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 658  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 658 | loss: 0.00073 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 659  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 659 | loss: 0.00072 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 660  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 660 | loss: 0.00072 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 661  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 661 | loss: 0.00072 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 662  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 662 | loss: 0.00072 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 663  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 663 | loss: 0.00072 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 664  | total loss: \u001b[1m\u001b[32m0.00071\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 664 | loss: 0.00071 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 665  | total loss: \u001b[1m\u001b[32m0.00071\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 665 | loss: 0.00071 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 666  | total loss: \u001b[1m\u001b[32m0.00071\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 666 | loss: 0.00071 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 667  | total loss: \u001b[1m\u001b[32m0.00071\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 667 | loss: 0.00071 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 668  | total loss: \u001b[1m\u001b[32m0.00071\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 668 | loss: 0.00071 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 669  | total loss: \u001b[1m\u001b[32m0.00071\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 669 | loss: 0.00071 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 670  | total loss: \u001b[1m\u001b[32m0.00070\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 670 | loss: 0.00070 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 671  | total loss: \u001b[1m\u001b[32m0.00070\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 671 | loss: 0.00070 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 672  | total loss: \u001b[1m\u001b[32m0.00070\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 672 | loss: 0.00070 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 673  | total loss: \u001b[1m\u001b[32m0.00069\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 673 | loss: 0.00069 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 674  | total loss: \u001b[1m\u001b[32m0.00069\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 674 | loss: 0.00069 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 675  | total loss: \u001b[1m\u001b[32m0.00069\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 675 | loss: 0.00069 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 676  | total loss: \u001b[1m\u001b[32m0.00069\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 676 | loss: 0.00069 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 677  | total loss: \u001b[1m\u001b[32m0.00069\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 677 | loss: 0.00069 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 678  | total loss: \u001b[1m\u001b[32m0.00069\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 678 | loss: 0.00069 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 679  | total loss: \u001b[1m\u001b[32m0.00068\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 679 | loss: 0.00068 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 680  | total loss: \u001b[1m\u001b[32m0.00068\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 680 | loss: 0.00068 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 681  | total loss: \u001b[1m\u001b[32m0.00068\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 681 | loss: 0.00068 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 682  | total loss: \u001b[1m\u001b[32m0.00068\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 682 | loss: 0.00068 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 683  | total loss: \u001b[1m\u001b[32m0.00068\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 683 | loss: 0.00068 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 684  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 684 | loss: 0.00067 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 685  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 685 | loss: 0.00067 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 686  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 686 | loss: 0.00067 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 687  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 687 | loss: 0.00067 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 688  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 688 | loss: 0.00067 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 689  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 689 | loss: 0.00066 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 690  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 690 | loss: 0.00066 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 691  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 691 | loss: 0.00066 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 692  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 692 | loss: 0.00066 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 693  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 693 | loss: 0.00066 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 694  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 694 | loss: 0.00065 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 695  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 695 | loss: 0.00065 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 696  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 696 | loss: 0.00065 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 697  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 697 | loss: 0.00065 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 698  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 698 | loss: 0.00065 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 699  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 699 | loss: 0.00065 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 700  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 700 | loss: 0.00065 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 701  | total loss: \u001b[1m\u001b[32m0.00064\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 701 | loss: 0.00064 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 702  | total loss: \u001b[1m\u001b[32m0.00064\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 702 | loss: 0.00064 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 703  | total loss: \u001b[1m\u001b[32m0.00064\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 703 | loss: 0.00064 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 704  | total loss: \u001b[1m\u001b[32m0.00064\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 704 | loss: 0.00064 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 705  | total loss: \u001b[1m\u001b[32m0.00063\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 705 | loss: 0.00063 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 706  | total loss: \u001b[1m\u001b[32m0.00063\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 706 | loss: 0.00063 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 707  | total loss: \u001b[1m\u001b[32m0.00063\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 707 | loss: 0.00063 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 708  | total loss: \u001b[1m\u001b[32m0.00063\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 708 | loss: 0.00063 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 709  | total loss: \u001b[1m\u001b[32m0.00063\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 709 | loss: 0.00063 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 710  | total loss: \u001b[1m\u001b[32m0.00063\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 710 | loss: 0.00063 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 711  | total loss: \u001b[1m\u001b[32m0.00062\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 711 | loss: 0.00062 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 712  | total loss: \u001b[1m\u001b[32m0.00062\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 712 | loss: 0.00062 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 713  | total loss: \u001b[1m\u001b[32m0.00062\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 713 | loss: 0.00062 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 714  | total loss: \u001b[1m\u001b[32m0.00062\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 714 | loss: 0.00062 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 715  | total loss: \u001b[1m\u001b[32m0.00062\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 715 | loss: 0.00062 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 716  | total loss: \u001b[1m\u001b[32m0.00062\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 716 | loss: 0.00062 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 717  | total loss: \u001b[1m\u001b[32m0.00061\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 717 | loss: 0.00061 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 718  | total loss: \u001b[1m\u001b[32m0.00061\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 718 | loss: 0.00061 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 719  | total loss: \u001b[1m\u001b[32m0.00061\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 719 | loss: 0.00061 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 720  | total loss: \u001b[1m\u001b[32m0.00061\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 720 | loss: 0.00061 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 721  | total loss: \u001b[1m\u001b[32m0.00061\u001b[0m\u001b[0m | time: 0.012s\n","| Adam | epoch: 721 | loss: 0.00061 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 722  | total loss: \u001b[1m\u001b[32m0.00061\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 722 | loss: 0.00061 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 723  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 723 | loss: 0.00060 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 724  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 724 | loss: 0.00060 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 725  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 725 | loss: 0.00060 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 726  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 726 | loss: 0.00060 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 727  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.002s\n","| Adam | epoch: 727 | loss: 0.00060 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 728  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 728 | loss: 0.00060 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 729  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 729 | loss: 0.00060 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 730  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 730 | loss: 0.00059 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 731  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 731 | loss: 0.00059 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 732  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 732 | loss: 0.00059 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 733  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 733 | loss: 0.00059 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 734  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 734 | loss: 0.00059 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 735  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 735 | loss: 0.00059 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 736  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 736 | loss: 0.00059 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 737  | total loss: \u001b[1m\u001b[32m0.00058\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 737 | loss: 0.00058 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 738  | total loss: \u001b[1m\u001b[32m0.00058\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 738 | loss: 0.00058 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 739  | total loss: \u001b[1m\u001b[32m0.00058\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 739 | loss: 0.00058 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 740  | total loss: \u001b[1m\u001b[32m0.00058\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 740 | loss: 0.00058 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 741  | total loss: \u001b[1m\u001b[32m0.00058\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 741 | loss: 0.00058 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 742  | total loss: \u001b[1m\u001b[32m0.00058\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 742 | loss: 0.00058 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 743  | total loss: \u001b[1m\u001b[32m0.00057\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 743 | loss: 0.00057 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 744  | total loss: \u001b[1m\u001b[32m0.00057\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 744 | loss: 0.00057 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 745  | total loss: \u001b[1m\u001b[32m0.00057\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 745 | loss: 0.00057 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 746  | total loss: \u001b[1m\u001b[32m0.00057\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 746 | loss: 0.00057 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 747  | total loss: \u001b[1m\u001b[32m0.00057\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 747 | loss: 0.00057 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 748  | total loss: \u001b[1m\u001b[32m0.00057\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 748 | loss: 0.00057 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 749  | total loss: \u001b[1m\u001b[32m0.00057\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 749 | loss: 0.00057 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 750  | total loss: \u001b[1m\u001b[32m0.00056\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 750 | loss: 0.00056 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 751  | total loss: \u001b[1m\u001b[32m0.00056\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 751 | loss: 0.00056 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 752  | total loss: \u001b[1m\u001b[32m0.00056\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 752 | loss: 0.00056 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 753  | total loss: \u001b[1m\u001b[32m0.00056\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 753 | loss: 0.00056 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 754  | total loss: \u001b[1m\u001b[32m0.00056\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 754 | loss: 0.00056 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 755  | total loss: \u001b[1m\u001b[32m0.00056\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 755 | loss: 0.00056 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 756  | total loss: \u001b[1m\u001b[32m0.00056\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 756 | loss: 0.00056 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 757  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 757 | loss: 0.00055 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 758  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 758 | loss: 0.00055 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 759  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 759 | loss: 0.00055 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 760  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 760 | loss: 0.00055 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 761  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 761 | loss: 0.00055 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 762  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 762 | loss: 0.00055 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 763  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 763 | loss: 0.00054 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 764  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 764 | loss: 0.00054 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 765  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 765 | loss: 0.00054 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 766  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 766 | loss: 0.00054 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 767  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 767 | loss: 0.00054 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 768  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 768 | loss: 0.00054 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 769  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 769 | loss: 0.00054 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 770  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 770 | loss: 0.00054 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 771  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 771 | loss: 0.00053 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 772  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 772 | loss: 0.00053 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 773  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 773 | loss: 0.00053 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 774  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 774 | loss: 0.00053 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 775  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 775 | loss: 0.00053 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 776  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 776 | loss: 0.00053 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 777  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 777 | loss: 0.00053 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 778  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 778 | loss: 0.00052 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 779  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 779 | loss: 0.00052 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 780  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 780 | loss: 0.00052 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 781  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 781 | loss: 0.00052 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 782  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 782 | loss: 0.00052 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 783  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 783 | loss: 0.00052 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 784  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 784 | loss: 0.00052 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 785  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 785 | loss: 0.00052 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 786  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.002s\n","| Adam | epoch: 786 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 787  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 787 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 788  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 788 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 789  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 789 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 790  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 790 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 791  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 791 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 792  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 792 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 793  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 793 | loss: 0.00051 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 794  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 794 | loss: 0.00050 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 795  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 795 | loss: 0.00050 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 796  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 796 | loss: 0.00050 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 797  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 797 | loss: 0.00050 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 798  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 798 | loss: 0.00050 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 799  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.012s\n","| Adam | epoch: 799 | loss: 0.00050 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 800  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 800 | loss: 0.00050 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 801  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 801 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 802  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 802 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 803  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 803 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 804  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 804 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 805  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 805 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 806  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 806 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 807  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 807 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 808  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 808 | loss: 0.00049 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 809  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 809 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 810  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 810 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 811  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 811 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 812  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 812 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 813  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 813 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 814  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 814 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 815  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 815 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 816  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 816 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 817  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 817 | loss: 0.00048 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 818  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 818 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 819  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 819 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 820  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 820 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 821  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 821 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 822  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 822 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 823  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 823 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 824  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 824 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 825  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 825 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 826  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 826 | loss: 0.00047 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 827  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 827 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 828  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 828 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 829  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 829 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 830  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 830 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 831  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 831 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 832  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 832 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 833  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 833 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 834  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 834 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 835  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 835 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 836  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 836 | loss: 0.00046 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 837  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 837 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 838  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 838 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 839  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 839 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 840  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 840 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 841  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 841 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 842  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 842 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 843  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 843 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 844  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 844 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 845  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 845 | loss: 0.00045 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 846  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 846 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 847  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 847 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 848  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 848 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 849  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 849 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 850  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 850 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 851  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 851 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 852  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 852 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 853  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 853 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 854  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 854 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 855  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 855 | loss: 0.00044 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 856  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 856 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 857  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 857 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 858  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 858 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 859  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 859 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 860  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 860 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 861  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 861 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 862  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 862 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 863  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 863 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 864  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 864 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 865  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 865 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 866  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 866 | loss: 0.00043 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 867  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 867 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 868  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 868 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 869  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 869 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 870  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 870 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 871  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 871 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 872  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 872 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 873  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 873 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 874  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 874 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 875  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 875 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 876  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 876 | loss: 0.00042 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 877  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 877 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 878  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 878 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 879  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 879 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 880  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 880 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 881  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 881 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 882  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 882 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 883  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 883 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 884  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 884 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 885  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 885 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 886  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 886 | loss: 0.00041 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 887  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 887 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 888  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 888 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 889  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 889 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 890  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 890 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 891  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 891 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 892  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 892 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 893  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 893 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 894  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 894 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 895  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 895 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 896  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 896 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 897  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 897 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 898  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 898 | loss: 0.00040 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 899  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 899 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 900  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 900 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 901  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 901 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 902  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 902 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 903  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 903 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 904  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 904 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 905  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 905 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 906  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 906 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 907  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.012s\n","| Adam | epoch: 907 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 908  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 908 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 909  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.013s\n","| Adam | epoch: 909 | loss: 0.00039 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 910  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 910 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 911  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 911 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 912  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 912 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 913  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 913 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 914  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 914 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 915  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 915 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 916  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 916 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 917  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 917 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 918  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 918 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 919  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 919 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 920  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 920 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 921  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 921 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 922  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 922 | loss: 0.00038 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 923  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 923 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 924  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 924 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 925  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 925 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 926  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 926 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 927  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 927 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 928  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 928 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 929  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 929 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 930  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 930 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 931  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 931 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 932  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 932 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 933  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 933 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 934  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 934 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 935  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 935 | loss: 0.00037 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 936  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 936 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 937  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 937 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 938  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 938 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 939  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 939 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 940  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 940 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 941  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 941 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 942  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 942 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 943  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 943 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 944  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 944 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 945  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 945 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 946  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 946 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 947  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 947 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 948  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 948 | loss: 0.00036 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 949  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 949 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 950  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.009s\n","| Adam | epoch: 950 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 951  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 951 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 952  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 952 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 953  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 953 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 954  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 954 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 955  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 955 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 956  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 956 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 957  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 957 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 958  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 958 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 959  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 959 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 960  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 960 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 961  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 961 | loss: 0.00035 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 962  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.017s\n","| Adam | epoch: 962 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 963  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.008s\n","| Adam | epoch: 963 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 964  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 964 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 965  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 965 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 966  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 966 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 967  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 967 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 968  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.011s\n","| Adam | epoch: 968 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 969  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 969 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 970  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 970 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 971  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 971 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 972  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 972 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 973  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 973 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 974  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 974 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 975  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 975 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 976  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 976 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 977  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 977 | loss: 0.00034 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 978  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 978 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 979  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 979 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 980  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 980 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 981  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 981 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 982  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 982 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 983  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 983 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 984  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 984 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 985  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 985 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 986  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 986 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 987  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 987 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 988  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.015s\n","| Adam | epoch: 988 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 989  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 989 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 990  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 990 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 991  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 991 | loss: 0.00033 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 992  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 992 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 993  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.006s\n","| Adam | epoch: 993 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 994  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.010s\n","| Adam | epoch: 994 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 995  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 995 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 996  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 996 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 997  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.003s\n","| Adam | epoch: 997 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 998  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.007s\n","| Adam | epoch: 998 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 999  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.005s\n","| Adam | epoch: 999 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n","--\n","Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.004s\n","| Adam | epoch: 1000 | loss: 0.00032 - acc: 1.0000 -- iter: 1/1\n","--\n"]}]},{"cell_type":"code","source":["import pickle\n","pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open( \"training_data\", \"wb\" ) )"],"metadata":{"id":"vFH-zKlXCGyw","executionInfo":{"status":"ok","timestamp":1660672754652,"user_tz":-330,"elapsed":73,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":172,"outputs":[]},{"cell_type":"markdown","source":["**restoring all the data structures**"],"metadata":{"id":"2GdnYUUAcmaf"}},{"cell_type":"code","source":["data = pickle.load( open( \"training_data\", \"rb\" ) )\n","words = data['words']\n","classes = data['classes']\n","train_x = data['train_x']\n","train_y = data['train_y']\n"],"metadata":{"id":"9BxfpWUlcsPn","executionInfo":{"status":"ok","timestamp":1660672754652,"user_tz":-330,"elapsed":65,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":173,"outputs":[]},{"cell_type":"code","source":["with open('intents.json') as json_data:\n","    intents = json.load(json_data)"],"metadata":{"id":"FtlS8jzvcxyR","executionInfo":{"status":"ok","timestamp":1660672754653,"user_tz":-330,"elapsed":65,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":174,"outputs":[]},{"cell_type":"markdown","source":["**load the saved model**"],"metadata":{"id":"WitwtA7Nc3zR"}},{"cell_type":"code","source":["model.load('./model.tflearn')"],"metadata":{"id":"b0xKfWRFc08z","executionInfo":{"status":"ok","timestamp":1660672754653,"user_tz":-330,"elapsed":65,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":175,"outputs":[]},{"cell_type":"code","source":["def clean_up_sentence(sentence):\n","    # tokenizing the pattern\n","    sentence_words = nltk.word_tokenize(sentence)\n","    # stemming each word\n","    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n","    return sentence_words"],"metadata":{"id":"u_iLLubec-Is","executionInfo":{"status":"ok","timestamp":1660672754653,"user_tz":-330,"elapsed":65,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":176,"outputs":[]},{"cell_type":"markdown","source":["**returning bag of words array: 0 or 1 for each word in the bag that exists in the sentence**"],"metadata":{"id":"2Klz_gzUdUZT"}},{"cell_type":"code","source":["def bow(sentence, words, show_details=False):\n","    # tokenizing the pattern\n","    sentence_words = clean_up_sentence(sentence)\n","    # generating bag of words\n","    bag = [0]*len(words)  \n","    for s in sentence_words:\n","        for i,w in enumerate(words):\n","            if w == s: \n","                bag[i] = 1\n","                if show_details:\n","                    print (\"found in bag: %s\" % w)\n","\n","    return(np.array(bag))\n"],"metadata":{"id":"Xk2uIN5ddZJC","executionInfo":{"status":"ok","timestamp":1660672754654,"user_tz":-330,"elapsed":66,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":177,"outputs":[]},{"cell_type":"code","source":["ERROR_THRESHOLD = 0.30\n","def classify(sentence):\n","    # generate probabilities from the model\n","    results = model.predict([bow(sentence, words)])[0]\n","    # filter out predictions below a threshold\n","    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n","    # sort by strength of probability\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    for r in results:\n","        return_list.append((classes[r[0]], r[1]))\n","    # return tuple of intent and probability\n","    return return_list"],"metadata":{"id":"Kfhw38VEddif","executionInfo":{"status":"ok","timestamp":1660672754654,"user_tz":-330,"elapsed":65,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":178,"outputs":[]},{"cell_type":"code","source":["def response(sentence, userID='123', show_details=False):\n","    results = classify(sentence)\n","    # if we have a classification then find the matching intent tag\n","    if results:\n","        # loop as long as there are matches to process\n","        while results:\n","            for i in intents['intents']:\n","                # find a tag matching the first result\n","                if i['tag'] == results[0][0]:\n","                    # a random response from the intent\n","                    return print(random.choice(i['responses']))\n","\n","            results.pop(0)"],"metadata":{"id":"iMy_l84ddh8W","executionInfo":{"status":"ok","timestamp":1660672754654,"user_tz":-330,"elapsed":65,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}}},"execution_count":179,"outputs":[]},{"cell_type":"code","source":["classify('What are your hours of operation?')\n","\n","response('What are your hours of operation?')\n","\n","response('What is menu for today?')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tH6Cc2cDdn3B","executionInfo":{"status":"ok","timestamp":1660672754655,"user_tz":-330,"elapsed":66,"user":{"displayName":"Vadranam Sai Krishna","userId":"03330564824110695438"}},"outputId":"3b43d77f-511c-4441-fea3-224de0c70cf8"},"execution_count":180,"outputs":[{"output_type":"stream","name":"stdout","text":["You can visit www.mymenu.com for menu options\n","You can visit www.mymenu.com for menu options\n"]}]},{"cell_type":"code","source":["response('Do you accept Credit Card?')"],"metadata":{"id":"Z5O0s0-ywrZ5"},"execution_count":null,"outputs":[]}]}